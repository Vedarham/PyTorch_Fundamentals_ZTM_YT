{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkIrOom2C80spO/9SdzkxC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vedarham/PyTorch_Fundamentals_ZTM_YT/blob/main/00_pytorch_fundamentals_ZTM1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00. Pytorch Fundamentals\n",
        "\n",
        "Resorce notebook: https://www.learnpytorch.io/00_pytorch_fundamentals/"
      ],
      "metadata": {
        "id": "JKJd-dcgMAsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMMU-SZBMVc0",
        "outputId": "93340b54-6201-4e80-c032-8e387cdacb09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k0YwUb8MzvD",
        "outputId": "2bd24a63-2256-463b-f7f7-7173a2ad3f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to tensors\n",
        "\n",
        "### Creating tensors\n",
        "\n",
        "Pytorch tensors created using torch.Tensor() https://pytorch.org/docs/stable/tensors.html\n",
        "\n",
        "by def: alll data type is tensor"
      ],
      "metadata": {
        "id": "XqzHh7GrNaGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scalar\n",
        "\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF3PQXkNOGnk",
        "outputId": "12cad97a-da32-44f1-885c-2fafb2a9132b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we7dal2GOwNy",
        "outputId": "b9c9441c-6d4e-47c7-b8f0-517fbd97dc24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get tensor bak as python int\n",
        "scalar.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A98cLqSNPLSM",
        "outputId": "bcf20841-88f1-41cd-9be8-d6aba2a4c416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector\n",
        "vector = torch.tensor([7,7])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piwhyaijPPuk",
        "outputId": "94834935-c358-4a7f-d4d8-94d12a532d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYbk60bDPjou",
        "outputId": "a64cad4d-32b9-411b-97a1-68570c2d35fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUVP2J3IPlAN",
        "outputId": "dd10a0af-f658-44b9-e0ac-53d0423ef816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MATRIX\n",
        "MATRIX = torch.tensor([[7,8],[9,10]])\n",
        "MATRIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz78fsrhPoDx",
        "outputId": "51c7377b-e45e-4716-d830-9dbeffe16778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVaKOXw4P6gp",
        "outputId": "2d718542-2812-4b74-a11d-264de905812f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x8WS7iaP-3s",
        "outputId": "2a306234-7cd5-4888-f189-06cfa2d936f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXdVO6bmQAtX",
        "outputId": "deed1d09-413d-4acd-bab6-cfa8aede3c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TENSOR\n",
        "TENSOR = torch.tensor([[[1,2,3,4],[3,4,5,5],[7,3,2,6]],[[2,3,3,3],[2,3,3,3],[2,3,3,3]]])\n",
        "TENSOR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENVSSdjkQQtT",
        "outputId": "fd8c24df-7655-41d9-a373-5ada52e3196d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3, 4],\n",
              "         [3, 4, 5, 5],\n",
              "         [7, 3, 2, 6]],\n",
              "\n",
              "        [[2, 3, 3, 3],\n",
              "         [2, 3, 3, 3],\n",
              "         [2, 3, 3, 3]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYIv-ldoQkPN",
        "outputId": "c0c132de-cca9-4169-d24e-752e7fe1197d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF5bGUePQtwT",
        "outputId": "26985b2a-cd88-4042-ce40-9c364767caeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqMwgWrsQwRn",
        "outputId": "78e311a6-65f4-469d-8080-ac15e343fee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3, 4],\n",
              "        [3, 4, 5, 5],\n",
              "        [7, 3, 2, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uppercase letter for MATRIX AND TENSOR IS conventional"
      ],
      "metadata": {
        "id": "j9t_fZldQ54T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Tensors\n",
        "\n",
        "Why random Tensors ?\n",
        "  They are important as many neural networks learns is that they start with tensors full of random numbers and then adjust  those random numbers to better represent data\n",
        "\n",
        "  `CRUX ::> START with random Numbers -> LOOK at data -> UPDATE the data -> LOOK at the data -> UPDATE the random Numbers`\n",
        "\n",
        "\n",
        "  Torch random tensors : https://pytorch.org/docs/stable/generated/torch.rand.html\n",
        "  "
      ],
      "metadata": {
        "id": "-UpRsfYbS6WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  CREATE A RANDOM TENSORS OF SIZE(3,4) OR SHAPE\n",
        "\n",
        "random_tensor = torch.rand(3,4)\n",
        "random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b697SuwATFsG",
        "outputId": "fe93eefb-a326-4627-8e25-91aeb2376ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6773, 0.1715, 0.3157, 0.0242],\n",
              "        [0.9679, 0.1601, 0.5315, 0.9573],\n",
              "        [0.5951, 0.2024, 0.6635, 0.9698]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "409a6ChFT2K5",
        "outputId": "97187278-e4d6-4041-ae5f-a222215424a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor with a similar shape to an image tensor\n",
        "\n",
        "random_image_size_tensor = torch.rand(size=(224,224,3))\n",
        "#  height, width , color channel // color channels can come first as well 3 , 224,224 like this\n",
        "\n",
        "random_image_size_tensor.shape , random_image_size_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWY7WdXgUPYE",
        "outputId": "fab1df7a-9fca-4d77-b1c5-620083afe243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Zeros and Ones"
      ],
      "metadata": {
        "id": "5hDeE-PGU12Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all zeros\n",
        "\n",
        "zeros = torch.zeros(size=(3,4))\n",
        "zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQVclrFIVw1U",
        "outputId": "f96933de-3b33-4f3a-d50a-93d540caa80b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all ones\n",
        "\n",
        "ones = torch.ones(size=(3,4))\n",
        "ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Hsfq3eqV5LJ",
        "outputId": "5b0f7b3e-4425-434d-9ad5-715f32c2ffe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v53uReXiWLLc",
        "outputId": "0e662e66-6c02-4f0d-c7a0-68cad365dcdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a range of tensors and tensors-like\n",
        "\n",
        "Ref. https://pytorch.org/docs/stable/generated/torch.arange.html\n"
      ],
      "metadata": {
        "id": "xXTQN_v3WNi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use torch.range() --> new ver. .arange()\n",
        "\n",
        "one_to_ten = torch.arange(start=1, end =10 ,step =1)\n",
        "one_to_ten\n",
        "# n-1 end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMovrZuSWaoF",
        "outputId": "d21cb9ab-3755-469e-bea0-8292ca631aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Creating tensors like --> same shape we use like method\n",
        "\n",
        "ten_zeroes = torch.zeros_like(input=one_to_ten)\n",
        "ten_zeroes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skka3z26WkUy",
        "outputId": "0a947179-ff4a-423d-da64-af8b7ac5e449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Datatypes\n",
        "\n",
        "**Note: ** Tensor Datatypes is one of the big errors you'll run into in pytorch & deep learning\n",
        "\n",
        "1. Tensors not right datatype\n",
        "2. Tensor not right shap\n",
        "3. Tensors not one right device\n",
        "\n",
        "\n",
        "Precision in  Computing : https://en.wikipedia.org/wiki/Precision_(computer_science)"
      ],
      "metadata": {
        "id": "GW6Pyoz4Xd7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Float 32 tensor\n",
        "float_32_tensor = torch.tensor([3.0,6.0,9.0],\n",
        "                               dtype=torch.float16, # data type is tensor (eg: float32 float16) for precision\n",
        "                               device = None, # which device is your tensor  by default: CPU -> change to cuda\n",
        "                               requires_grad=False) # whether or not to track gradients with this tensor operations\n",
        "float_32_tensor\n",
        "# by default : none = float32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO2ALW8BwYHc",
        "outputId": "7952241f-c1c8-47a5-f92d-084bdb38213c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ouwyQLwwmTN",
        "outputId": "e0e58dba-de12-4976-d483-77e039383b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor = float_32_tensor.type(torch.float16)\n",
        "float_16_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Otnwn2oawq6q",
        "outputId": "b455e798-1a1a-496a-ad06-df50975eadb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor * float_32_tensor\n",
        "\n",
        "# Some DataTypes would have un into error of being not right DataType ; but some , like this provides results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6f4bfQ2-EWO",
        "outputId": "24dee1b2-8370-49b6-f72a-d1d7d617bf0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_32_tensor = torch.tensor([3,6,9], dtype= torch.int32)\n",
        "int_32_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y6_kInU-mG7",
        "outputId": "a80254f9-f234-4ea0-c7cc-11912c003590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 6, 9], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_32_tensor*float_16_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MgssrZ6ANSC",
        "outputId": "8c564715-8192-4179-9a2a-75b082e0fbc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting  Information from Tensor (using Tensor Attributes)\n",
        "\n",
        "1. Tensors not right datatype - to get datatype from tensor, can use `tensor.datatype`\n",
        "2. Tensor not right shape - to get shape from a tensor, can use `tensor.shape` which is equivalent to function `tensor.size()`\n",
        "3. Tensors not one right device - to get device from a tensor , can use ` tensor.devices`"
      ],
      "metadata": {
        "id": "T98sCFBnAQ1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Tensor\n",
        "\n",
        "some_tensor = torch.rand(3,4)\n",
        "\n",
        "some_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7trajBtcDIA8",
        "outputId": "e0000d13-1998-44dc-b9b9-1e597735a348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2163, 0.4450, 0.9663, 0.1120],\n",
              "        [0.4731, 0.7861, 0.8990, 0.2944],\n",
              "        [0.0241, 0.3474, 0.3427, 0.1218]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Find out Details about some Tensor\n",
        "print(some_tensor)\n",
        "print(f\"DataType of tensor : {some_tensor.dtype} \\nShape of Tensor: {some_tensor.shape} \\nDevice of Tensor {some_tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRvW0rdJDTO1",
        "outputId": "78b70012-c4a5-4fd1-bf66-eeba0dd35966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2163, 0.4450, 0.9663, 0.1120],\n",
            "        [0.4731, 0.7861, 0.8990, 0.2944],\n",
            "        [0.0241, 0.3474, 0.3427, 0.1218]])\n",
            "DataType of tensor : torch.float32 \n",
            "Shape of Tensor: torch.Size([3, 4]) \n",
            "Device of Tensor cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulating Tensors (tensor Operations)\n",
        "\n",
        "Tensor Operations Include:\n",
        "* Addition\n",
        "* Subtractiom\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix Multiplication"
      ],
      "metadata": {
        "id": "1a6Y4oFXD3et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Addition\n",
        "\n",
        "tensor = torch.tensor([1,2,3])\n",
        "tensor +10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY1XztrvFLxs",
        "outputId": "994b63cc-7d3e-40fb-8a07-14759d772979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiply\n",
        "\n",
        "tensor *10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyiRgewyFyos",
        "outputId": "448d8d0e-48d4-44b7-e11d-9028f48af8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI-uZT_GF6F7",
        "outputId": "d5d3fc96-d5a1-4c90-a25d-a53cc7518b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor *= 10\n",
        "tensor # reassigning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmPg4NE6F7Wb",
        "outputId": "e3b140ea-e156-464c-a34b-eb2ee4ebc083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subtraction\n",
        "tensor - 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B0xjPA-GBEu",
        "outputId": "2086f737-bbed-4bdd-ef95-9404c58f8dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Divison\n",
        "tensor/10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njVGT6k8Gmng",
        "outputId": "45680655-d0f0-417a-d2a6-5b13473a69cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try Out PyTorch Inbuilt Functions\n",
        "\n",
        "torch.add(tensor,10)\n",
        "torch.mul(tensor,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld0B2Yl4GIs6",
        "outputId": "ce385139-5d59-4b1a-85db-477cc35b6af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([100, 200, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Multiplication\n",
        "\n",
        "Two main ways of performin multiplication in NN and DL :\n",
        " 1. Element-wise Multiplication\n",
        " 2. Matrix Multiplication ( dot product )\n",
        "\n",
        "\n",
        " There are 2 main rules, cared off while performing matrix multi.\n",
        "1. **Inner dimensions must match** : `(x,y) @ (y,z)`\n",
        "2. **Resulting matrix has shape of outer dimensions** i.e. : `(x,z)`"
      ],
      "metadata": {
        "id": "nui-bkd_GYdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print( tensor ,  \"*\" , tensor)\n",
        "print(f\"Equals: {tensor*tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj4bAjS6GgHN",
        "outputId": "931c6ff8-b745-4afe-c46d-1a02bcdb2008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10, 20, 30]) * tensor([10, 20, 30])\n",
            "Equals: tensor([100, 400, 900])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix Multiplication : uses very less tome i.e. 10x faster than forLoop\n",
        "%%time\n",
        "torch.matmul(tensor,tensor)\n",
        "\n",
        "# MM by hand:\n",
        "10*10+20*20+30*30\n",
        "\n",
        "#Using for-loop:"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5gHAnRvHheX",
        "outputId": "0c517ed9-3e0e-44eb-ab92-14eb9bef9674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.43 ms, sys: 0 ns, total: 1.43 ms\n",
            "Wall time: 8.49 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1400"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "value =0\n",
        "for i in range(len(tensor)):\n",
        "  value+=tensor[i]*tensor[i]\n",
        "print(value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8tCv_AMHtxA",
        "outputId": "d741a4d3-3369-4c2a-ec7c-9b34e3ecb98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1400)\n",
            "CPU times: user 1.58 ms, sys: 0 ns, total: 1.58 ms\n",
            "Wall time: 1.54 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One of he most common errors in Deep Learning : Shape Errors"
      ],
      "metadata": {
        "id": "muPEkwfZG1EZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shapes for matrix multipliation\n",
        "\n",
        "tensor_A = torch.tensor([[1,2],\n",
        "                        [3,4],\n",
        "                        [5,6]])\n",
        "\n",
        "tensor_B = torch.tensor([[7,8],[8,10],[9,12]])\n",
        "\n",
        "\n",
        "torch.mm(tensor_A,tensor_B)  #Alias for matmul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "9STPI-JTJ0nM",
        "outputId": "38c7db84-54e2-4d51-899e-2e9904345292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-1fdef4598e9e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensor_B\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#Alias for matmul\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_B.shape , tensor_A.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf_CCEkhjlJO",
        "outputId": "27bd9fd3-a49b-4387-bdd7-c02f10b3d214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 2]), torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fix our tensor shape issue , we can manipulate the shape of one of tensors using Transpose\n",
        "\n",
        "A **Transpose** switches the axes or dimensions of a given tensor\n"
      ],
      "metadata": {
        "id": "R-Z4E6asj_Yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_BT =tensor_B.T\n",
        "tensor_BT.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myKQMFH5kWAc",
        "outputId": "8d1c9af2-7821-4f2d-e289-c65a47c801f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.mm(tensor_A, tensor_BT)\n",
        "output\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NED5f4vwkaia",
        "outputId": "0a20e170-5dfb-4ef3-a6ec-c9bdb3bc25d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding min , max ,mean , sun , ... (Tensor Aggregation)"
      ],
      "metadata": {
        "id": "3OXvxGFqk4d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(0,100,10)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CQabmLElrrC",
        "outputId": "bd39340f-095c-4046-f2da-8b5cb01c2778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.min(x), x.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht8YrJbBlzVX",
        "outputId": "8831dd5d-261c-4f11-bb83-45ef68898247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0), tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(x), x.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji_YPh3Tl3P7",
        "outputId": "a66ca109-981c-48d7-b7d7-336e95c60a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(90), tensor(90))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.dtype\n",
        "#x.dtype is int64 so error hence convert to Long to perform Mean (float or complex)\n",
        "y = x.type(torch.float32)\n",
        "torch.mean(y) , y.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcy4-gRYl7yX",
        "outputId": "136d2079-1852-441c-aa41-dc69ee7d283a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(45.), tensor(45.))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(x) , x.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFkKaStbl_oX",
        "outputId": "864291c0-2493-4a62-a572-8e97859f1f84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(450), tensor(450))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding positional min and max"
      ],
      "metadata": {
        "id": "Po06TJfRm580"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the position in tensor which has the minimum value with argmin()-> returns index position tensor where min. value occurs\n",
        "x.argmin() , x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l589w7tSnTIP",
        "outputId": "2ee72034-8374-4cbd-88fa-30ebd9b9a078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0), tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the position in tensor which has maximum value with argmax() -> returns the index position tensor where max. value occurs\n",
        "x.argmax() ,x[9]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm9e5TsrnVLf",
        "outputId": "4df7c37b-116e-4561-9826-77046d32e2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(9), tensor(90))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping , stacking , squeezing , unsqueezing tensors\n",
        "\n",
        "* Reshaping -> reshapes the input tensor to defined Shape\n",
        "* View -> Return view of an input tensor of certain shape but keep the same memoryview\n",
        "* Stacking -> combine multiple tensors on top of stack each other (vstack) or side-side (hstack)\n",
        "* Squeeze -> removes all `1` dimensions from  a tensor\n",
        "* Unsqueeze -> add a `1` dimension to a target tensor\n",
        "* Permute -> Return a view of the input with dimensions permuted (swapped) in a certain way"
      ],
      "metadata": {
        "id": "ziX2cFRHn9fI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(1.,10.)\n",
        "x\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SR1DaAXppdo",
        "outputId": "ba994644-b64e-4671-8ed7-cd993c8f4c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra dimension\n",
        "x_reshaped = x.reshape(1,9)\n",
        "#  9x1 =9; if would have taken range 1. , 11. then 5,2 or 2,5 would have been compatible i.e. belong' size of 10\n",
        "\n",
        "x_reshaped2 = x.reshape(9,1)\n",
        "x_reshaped , x_reshaped.shape\n",
        "x_reshaped2 , x_reshaped2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXETSLSZp8Eq",
        "outputId": "b9e03cf8-1dae-4d64-a13f-aa97b7a9b3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [2.],\n",
              "         [3.],\n",
              "         [4.],\n",
              "         [5.],\n",
              "         [6.],\n",
              "         [7.],\n",
              "         [8.],\n",
              "         [9.]]),\n",
              " torch.Size([9, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the view\n",
        "z= x.view(1,9)\n",
        "z , z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-e7cR8-qG_6",
        "outputId": "067e33b5-ebfb-4129-d13e-fe9eec284d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Changing z changes x(because a view of a tensor shares the shares the same memory as the original input )\n",
        "  z[: ,0] = 5\n",
        "  z,x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBc9Qh0Xq1aD",
        "outputId": "0c9a6613-4633-4060-f5a1-e7aa4a370145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
              " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack tensors on top of each other vstack dim =0 :: hstack dim =1\n",
        "x_stacked = torch.stack([x,x,x,x], dim =0)\n",
        "x_stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDgoX1y2tYvo",
        "outputId": "ac3986bb-10fe-4899-bcc2-cc9536626ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using squeeze on previous tensor :: torh.squeeze() -> removes all single dimension from a target tensor\n",
        "\n",
        "print(f\"Previous Tensor: {x_reshaped}\" )\n",
        "print(f\"Previous Shape : {x_reshaped.shape}\")\n",
        "\n",
        "# Removing extra dimensions from x_reshaped\n",
        "\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\n New Tensor: {x_squeezed}\")\n",
        "print(f\"New Shape: {x_squeezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV9mtDcYuBgc",
        "outputId": "6f79e8a5-799a-4c36-8f20-508c42a56ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous Tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "Previous Shape : torch.Size([1, 9])\n",
            "\n",
            " New Tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "New Shape: torch.Size([9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.unsqueeze() -> adds a single dimension to a target tensor at specfic dim(dimension)\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim =0)\n",
        "print(f\"Unsqueezed Tensor: {x_unsqueezed}\")\n",
        "print(f\"New Shape: {x_unsqueezed.shape}\")"
      ],
      "metadata": {
        "id": "b9eZwIHMwSjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e959b9d5-0e52-4c2f-eb9e-a7c5f70ea1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsqueezed Tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "New Shape: torch.Size([1, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.permute -> rearranges the dimensions of a target tensor in a specified order\n",
        "\n",
        "x_original = torch.rand(size=(224,224,3))\n",
        "\n",
        "# Permute the original tensor to rearrange the axis (or dim) order\n",
        "\n",
        "x_permuted = x_original.permute(2,0,1) # shifts the axis 0->1 1->2 2->0\n",
        "# L2R: 2 maps 224 0 maps sunsequent 224 and 1 maps 3 so we want order 2,0,1\n",
        "# Note : dont consider indexing just consider mappings and shift\n",
        "\n",
        "print(f\"Previous Shape : {x_original.shape}\")\n",
        "print(f\"permuted shape: {x_permuted.shape}\")\n",
        "\n",
        "# x_permuted shares same memory as x_original as permute is a view"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMPTqCoUU6OZ",
        "outputId": "2a342b7e-1749-4fc5-8c4a-a4798ff785f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous Shape : torch.Size([224, 224, 3])\n",
            "permuted shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing (Selecting data from tensors)\n",
        "\n",
        "Indexing with Pytroch is similar with Numpy\n",
        "\n",
        "![3d-array-breakdown.webp](data:image/webp;base64,UklGRghSAABXRUJQVlA4IPxRAABw1wCdASohA5EBPm02mEkkIyKhIbNZOIANiWdu/kY/pvV+yT+mfk76V3Vz0a/Tf4B/Wv77/ZP//2wf1X+AfwD+m/wDmFEA/Qv+kfi/+//3l+Afx3+Pf0b+vf1XvNf4DzBKAH8U/oX+L/pH+O/Xj2wfzPzBJCf4V/Xf9p/efQu/mv8v/nPUZ+Wf13/gf5v3L/yr+gf6X+8/6H/ud7N+1XskfwD0g4ayAzX3yBAqP5f+OX45awB/F/xi/EbbAP4B/Ofxi/oG6cfyv8Zt4l/o/4x+yZ+wfjN6CP98/s33AfQT+GfxD+nf27+4f3P+zf/zmAP0i/uf63fMAVX4A68f570HXj32c4p/KvmB/Cvpl9b/Lf8pNYM/kf9s3qmp/+O8j75f/k/zM/oHOB3Fn+C+zj4S7wagB+Vf9B/WvxV+kL9z/4P+C85vzl/wP8T8An8l/ov+7/OjvAfrT7In6y7noXZ2jubYTf9LYRtIk+aTsqD9WztHc2wm/6WwjaRJ80nZUH6tmyherZ2jubYTf9LYRtIk+aTsqD9WztHc2wm/6WwjaRJ80nZUH6tp4m/6WwjaRJ80nZTNu2+3MsuMCXXPABO48RQTm4NgSZR4iysJrfbWOyZCvaPPdud+LLWE2X9P+0iT5pOyoP1bO0dzbCb/pbCNpEn7H1bO0dzbCb/pbCMq3kJTW3+rZ2jubYTf9LYRtIk+aTsqD9WzuZP9LYRtIk+aD74L10bCL6bY8OQnt2UahNydR9LCGO1lA0wPwqiyY+rZ2jubYTUcxbCb/pbCNpEn7H1bO0dzbBDpCUvF4YuGfH0T/Vs2lpJtnaO5thN/DUUmaHEpgW7zSdlQfq2nib/pbCNmGDI4c6LwYRHBPM4JRHBPM4J5lPKI4IM4UH6tnaO5xwaU7SkXsRnnOWYyDdewubYTf9LZHJ2VB+rZ0xCVNh909uzhhIcC+NXQsKuU3aMVn8SD/ejIPxee38lnUSxaaEHrQuZm+U0Kiyr9h/3oZUzVwpk+aTsrLB+bYTUEBj0rX2dDYZcgRRiHuDb6JDB1xAxG0iTYhEFwebMPmAO0hwC9Nzy5IcwzR3NsJv++pPmk7Ek50b4/BTwIoIiingmvT1SWFsuBWxof2NC6ZlZcKGIgVrn92+8morsL/pbCNpDkC0ktrziFusFK2WjUxXkfm2E3/fUnzSdjDXhm7in88x4sOtjtNu4ZZgmBJB9Hp9igehL136AQY1VQifmSvXTNXc4XbYadx5IoPT8UrW4KB2cRSQVwo/u0WT6mMmQ2wjaRL29WztG/SADOFLm5BxfJYJyMMrZ8fw8r3HbiKMeJjIdPBihHsm+9DaE4uh93ZK9xa0SZ/y2wAg80kaubYTf99SfNJ2Jshps3HrAJM4Un8hqk5+xnqBzRcX+RybX2ND+xoXTMrLhVtSC5S1DWaKSFI2fi+k+lsI2kS9vVs7R3NrQKKVCCwuk1TnwWg+AQ1loX/SBDHWGsD3MWjW3mUa0zxdfE6fwj69s7R3NshLSJPmk7J1PNZnkLhkiRubW9IoOq6vQ5nscDugTglFx8xz1bO0dyrC2E3/S2RydlQfq2Z8SIdHZnbG1whKeQJTQunq62W2fWheaksQcHFxvvusthN/0thG0iT5pO26O5thN/0tFCjbp6hsOvTFIBmUESGRZcUP12oOZY9DYfLZ2jubYTf9LYRtJfVB+rZ2jubYTf9K7bXboHW4stG6JmqLl/SPYrFu223eEbSJPmk7Kg/Vs7mT/S2EbSJPmk7Kg0732+2ukD0EfJyszO0NLT1NXXzO7SdOWkSfNJ2VB+rZ2jvHaoUyfNJ2VB+rZ2Z3nbDrwExjzdWfRwEvsWLWiWtk+aTsqD9WztHc2yEtIk+aTsqD9WztHc2wmJ9Hy6IE3VoFZsiWrFzkjPtpEnzSdlQfq2do7x2qFMnzSdlQfq2do7m19QBMQ1mi4vBjmcE8zglEcEoinlNkA7m2E3/S2EbSJPm1Odo7m2E3/S2EbSJPmk7KcwqF5if6xsHc2wm/6WwjaRJ80nZUH8L1/lfr/wXzz2X4n6D7Z8Z9M9v+Q+pe6/K/X/gvnnsvuFrbkCtalCra0Y7Ot0ksXraL8LKJKua42bdtX9k5PhY7uDDqRvBcQ2SoPBf6/8F889l+J+g+2fGfTPb/kPqXuvyv1/4L557L8T86b9WZnaGlp6mrr7G1t7m9v8HBxcfJ7KmBCWTze9ze3+Dg4uPk5WZnaGlp6mrr7G1cMf4ODi4+TlZmdoaWnqauvsbW3ub2/wcHFtrj6jM7Q0tPU1dfY2tvc3t/g4OLj5OVmZ2f+AAP73S2ae+VbxJR4G3ud43OLh/nVCa/D3qzXSs7cAO+m98kldTDUTuED+Z7W5oNux/m9H8Snr6GemDxR0u+8xFO+cxQAAmPcn/r73yDAWiGfcX0tWsgBPGxJ/37HRyhVqASb5hrkojin/4eqpQvQtAZpIEIdnP57wdwyyG0jCIx9y18UoS566XMG4VVpN692F+y0JwmbvVu0REz1XZwonjYVL1H/EWONVSfND6fNSlRr/HBMJmJcORnaq/MHiLnfYWt74wW7Zy8e9z9MRRAbbjnxeJjM//jsnZ//hA/5F/RBrE/yx1UQMgAXO16Hx5dqZ0D2EvYV2/ladAQYXCbOjv8lAGYCvpeBXR522ridl7Za4NvHxXFd+eeLTTc3O+O14AFGr/nTN+XkEIKugDV9fJfsrCXxJOPBqqoaQji9/wnt+amj5od64LBfgqvnhDQTA5gKr//1V5KlyGcyJ5xkKWJxZ7Uue8sikYqu+svaaSk9S5eQWiCONMEeo/dXVQVF9s+S8tUTdPlV8MXcyQ+baFu8ST77mVMLYuwP4P85ZvbOLTT7+gSCZL6zJOBlv/ImBMMSnVtrLO6LkxNsEX8pRZCevniVi7FVXaA7oE79UUqXrsLL6Ex+iFjzT5ms9QOA9+HEL05lS60sXEqQjvdFgM/yG09a3/q0tYNd/9EwndPjgnxgnTY6wBVsq6yCDgD5DikMOsEsrEEro/KqfxeuVWmghp9DTndtrP+VVVWfZfxfvxmEpOizNY1TNbYkH5bWvcQb8Tfh+ZaqyzXQ8ZhejY/38V/4IrsDBhMwS2eWiP2OHhLs/dfpHwchW3hZyv/aKEk/4jkoIU18OqiMUYMLaXQ6a5lNAFeopAGoQ3H1QjnxOn3CjSCthpY9PiHWSfAYksIYLthwEHutHl15p3XLWsaSJtJGunL9Wi+jDdjDFoxxb4lb1T3SkdW/bZPjYn9BnmKhNU72Z6A+DSGZPBfrtv4gd4tTZEpQghdEvsAkoV0I+ePe3+4rppLM0LYtiR+g4Xq2FnUU0oFG//L4fx86jT/k6ByE4fkO0vsfHl8ZtqaZD4mXMq8vuvSLuCUdNEMTygX//kyuXPL4ocY0Z+AMCyLhKrmzCAERUZ7uZm64V/M/ryX9KRxc9z+5RZqsrtCYpQe76MSkcdzidIe+//8bGl/133+3h466tmFk0S2ZhqWvJpSjqRGRnXZnIw2IqgyjfYWMH3coUnTZIdYllL//TrMeD5mqz//1BDXDcs4bOnWjY4mPHM15GomX+CLpENTMLcS3QNVVbnPxrNaU4ulo8PtDOD3IdA4YBWritu//z6fR0xPZyn+8DDhtQ+rpzxoOFzgYVAD5w3owRfPBzgAVQYLJktm2A6Np7EEmhd5oeyyan4QdJSBN5ersQ0hEHGdxleP/7Ok4bwnsjCkOR34uT4br723+E2yEdj+tv8JtGKq3WW2jQpgr6qSbR7D4MAbxGUH8cEu/ZSYvHlKfrxE166lF+IePTPFGVUYuqAGz/7yXfhJwqmZhqb/TxEEDW0Xu6QP/Oev1wd3RNLJYHtcgVC+zVw9ahCC0W7pntHIU85x7yGBY3jv/+4eCoiUh39yBCISUCGhjGmOKEz4GAoj//qHm+8KXHC8WcRM1TVuo/IMQfqUVgNwsT//3nerqxhiYMdzw76freVg9IHsG62oKrRGwzSVwjhnfvPT/o6PLt3ZBJa6zdResjuY+8AvNbuFPICnwFGOmFgVxDOy9HilRsBmGgfB9UD9Xj6dzp5Dl7CDa6qwMRjHcGe4bv79uTP/312JKyRIlSPy/0ML2OrcIuO8e52bUfyaeARS4gNnX/U6DxhlwI2DAkO3aIpbiAd2jnlG51nzT2KOyxOEZStOP/hMr2FJfxj/v+VN4laliK31EtK8dsqIntxmUhk1W+1WEMoe8MQC9/5nbqQP5byxlTPX90LPFzf10iwUf/1JAMKyMH8HKJfVkCxZGqwTghXQJZptNWw4km3a0we2ozUNfvd1oNVYp/e3MdjnmPxiyRbnjdmCv+6zpDTRnIQ1qBif8VZ0MydwsfGl0Dk3WQYX2lUbmhirebCdV2XZmoJa0ZHMI8c9zqoY1rZuZxnAQ0fU4AM78uZT2+OwQP2NLCQOfLXjXx8qj6eBDOux3W3Blty+ID4gQeJOAHmmF1wVcYleZY5yR9Si8dPH/1tbrLGSk/ddvjZ/ecihcqepnpMqkoI6co6dmw2j6SK4vfF47nGzSPQ6PFHfnHeS7puVgqW/+ygHA3LntLsNRfrbMFnrndy/VU76EkstQKa4p+jhuVs9NhCPOzzzND8APysPjuLPcSTncJLJHNDqFltmrfHb2k0nFdSW+Kc0dPwRKuCNyx8KPrFaWr9TKnC1YS6edRV+GCyu3jqo6lCX1apqZrywSow4iLtz/XyNzCWlEP9TpveLO9eZOQ1BXY7TuYuhI6cy3OGcojSkfgCXL69szoF79XiOduSzMecIVL/yPlAblWAvX03wDYGmZHyl7QrQh3tFIH9VI+bniJv56DXbzHMpDIbQnSuSpMqO5aAvAAlMK4kdhtJznTOwoOi7aeuZtYlQ8QhwIzBDYjEUyBTLQiF7DM60bEy6COrTmpOvC2BthEQpi7PuN6mhYYxZvN2Bs/+XFBPqP+nhjVcAbJISuczvPar4RZupp+ym091VK+5kpmJWuilx958LVZicHghUWwAfGAFv6u+83I3I3H+ioFB5m4UoXI3mLDeCHkOnR12b5Tgksu8yiNkSAI1X+Hpoul7eXjfYfDzlAwmhW2ADcxW8kkLGzCU8qLSKDhfDrR8zLfKG85vS233tNyn/KwIJfC7OL4Js3cbdGrOgGH9Hzkr50XZXLms2Dl75EUgsxaKie6fZFGHNFft23aSKY9h/Zgq40soc5DdF7fBt61cumpbMk5rLVWQrnDs4Hb0tzzl8W9mRWlTeX/0Cd87CHBcXzn9IpF2letN1pUod29ggnpA7tBpetcpfHKHVuU0QhAwvO60WmrW6BmuyLSEyTskL6ZnngKTBjj++SOuA8lVrk1CmdnY+lbY0mEH71yNdwUgNOyheIZV8e5Q9yff8AdT2oJwnhaxRXsZKu+p7XPubDWqpET2ENeu937Yw+hdoZr5XLyQOdlae97E4CT526z+W2d3JI+RMU9g6NsA8560Kn5O8+PWXuyxau/v93/l+db3h3+FDOzsUj6a1kjRrNkzBAqlSTUAaN1oYQGPuODdKzBAfGf4S72tbys9jPt2QpH9uL2oSiMMy5sH4KBOPa50As1OijFsijNG3njv8XEwbn1MdWAyXiJzIF4X5z8uTiEAA4htumBFNMGcddqXYnZsAtrkeTNl4mSszsoDXEqzXLPezMNBDdwFe4BB5BQAqQzLIdi6UWFNS2CytmEtU8EDanRAd52yP6xq0AFzVcYoOJJW/+DxcIF4OTf6B7xHiEXoKTNBky1idJV4jFVL9iI2EOolIEIjQLwG5U8OO98f/0X4JJBePs1GMMu1HZyXOZL8ltOeLhsKMndvSYpVKVsiSj4K/ba19RvVJtK27REk9sf/8j2otRg4GTsaC4GVdyEAk5yeHy2/7SP61XvnfuJQ6/mLu4tb3Izvd1fXbJBuWiabZX1H/yo0qCp3b2O76IoHA5aCOKjdwy4/+mWeg4UPQWOvvyPbpOMBMDPJBccLIBuDiqGdCBwRJHncL0aNG+e7r2tByxHDF2zCWqeCBtdEB3nbI/rGrQAXNVxig4klb/4PFwgXg5N/oHvEeIRegpM0GTLWJ0lXiMVUv2IjYQ6iUgQiNAvAblTw473x//Rfgm+mk4+zUYwy7UdnJc5kvyWj7MgE+XmNT8CjM+GfdZElHwV+21r6jeqkPTVDYLUDz5Q/8j2otRg4GTsaC4GVd1x51eUF7kqutvFF0kZ7OBiHWlDraTuRwXxkY4H665y9koP5AkX0HT4h2gGKAA0xGDrJIFFPL5oh14wzsmIq4UH+j/DrgPN/sXNLIb2DA8BWWTL8ttiFMGfxlZDHe//bin9UJJ8ocpPro/C/Yi6YdJn2fM/+hT4aTy4D/m8qAeDB1PR/58gKpu5xNNQaWFZeZ00nH/MSh12RIEDzdU5bxXal3LRgUIrKA54mYZaU05Xj/2yHCxEzbwmivsiCaK/OdSUpt2Yx9NcGCRQE3nLaVkxzOS460uQ2cziBZw+/DRtKTKM5V16d2n9O/5s8C4annsf5nhe+wA+xgQ7QMTxhuVE0drrDZUYNKrJIcdFQRQJ13Z02KzMeBfeumFN/a7N4g42BHxZZOb4f5QI/0sP5eF/YVRlQjfYNa2bgKNPETNSRlj39ihSe2I1VEr5/C6e+g+kj+s/62B4696UxlGZSiq0a80y+CNqPwyMCXYLvJeOViTHt8h7F75spFUFz89d/fpRPKUxiKqXyumbLgtIj6r2pk+z4+JQCekB1p/nrX/5Zn/rTGglcuP38EutJv/ZuZQPQHBsM8RUxVpXC2JIlFIuZf72edmB+oL1N8irar7AGvpV/8Q/7ATRShUGeN8cQAmfvYJiot1p2g6A/u2BNP+pt6BKpaOqenwrBfB6U5rlTgfQX9RgVKosuDQ8KtJIZq9gauy6fNEQ/85YbSSGDaTvxe/XfcoScMNFrUdqRZX+VAtfYUrAYdBqVIdr7jxGfpohYytiqcZLhFJ01vbzgDDdPPDBoMivpjmNYAfLZHuzKJGluz8Px7DGyQOvuREZ3HnjiXTjuf+ENY9eHnlpsDN/khECc24tC1wHNlndeVEQqL5h3OA9TTqJEEYIvnceT2cVEsHO4+3ilxH9+6OKX5KMgAuPtCqzuSJ+1c4fVh+8301ebHl/09pTKhDBukxWdOpPx9hkid2r3rltErlEJX+Y0swRfNF4d6k91tyDAdvIfzZvSFt6p3NrmYa1dYvXpuq1FnD2VjLdh57QBOVmq4Pj/W93gmUwKxFCgHAA+GMdDJkqDHSBAyq3PVK4grblT8v6TVgg1xOGDMXA5QjTKZei2CgJc+GUZDYEaYVo2uqRMwhMA8JOM+ifbLu1YHMRXO6KIxEzwI7ZbLvuP87t92X9PmmKQ68lrJQUiN5BQG4PTkv28MtvPgbQCkHDpGO2Kysimopys/fWV5TNUBLX6Qo8uaRJgp586orQmNEE2tDorqj+Kg0PKxzpsl+YZ+CT+fH15/f05nXROm1Lm8g2GHPLuOYLyFiCB5Kez2Yy60LUEt9/dP17XU/6MPEszB8AfaP5BDXfLyly3osCnKUW+e5/ufrdnChFRhnNduzhFPLsOuBwDzq4bC0d+6XWJJb71ryYmMjyMyTSQn5BJrhpmYS3/BTRpLjjY8uAjI2URH9O3rcWkW7VO28rWpzy/pvZ31GlUbgqRQLLa///sT03/8eHAijo+eG0moflKLqcDN6a52AkW3RfAieVkqcYzAqpzAA9TBnrOi5c2X5NgEe50gnwHiAtt8v9lC5Rvt6X32Hd9EvdIb5/1DJfm0/wOuVDhwOHgvbuKI+4chFxeoeaPKdY9AC0DcOeZf7hAjrCx3oARb3omhi2U2EkQPdAfmQbdLAqDPFPItrrDwygHh/1eCqF3yNuxgPBYslHPU6xr/d+9DOui/UAVByIibpksWmA8uPnWTS4Fkw6palgn2nWc9PTj1EsaOH+eOrA8DiFl2ln+g9pdOVf/7+ddfp48IKAdUTpdAQU0tY012Nb0/f/sHpzJ0FEf/CGprDvhbWuwgcr4QCNYd+VY7xeyFEIa2kBF0AG67mOypLI7ptws9hFgWetBUKxzNwTsof3NZt0/vv6FXYH6lfpvsS80vQn6uxau2FGr2Q/xUf/id+Af4OQLuMMiMxdPEWWURnxoOjAQKjmlJLsRbuYYoesEs9hFgWfhEv3f/AWtAeD+MutQC7mBn6d7Qds7kiwzeEei3sWnw+uVDhwOHgvbuKI+4chFxeoeaPKdY9AC0DcOeZf7hXdXIM5/HuSxAJIitSXJIOVV41g26WBUGeKeRbXWHhlAPD/q8FULvkbdjAeCxZKOep1jX+796GddF+oAqDkRE3TJYtMB5cfOsmlwLJh1S1LBPtOs56enHqJY0cP88dWB4HELLtLP9B7S6cq//3866/WlTFmgUHtxxrbEWrhtIX7lq+xj/6cUB2TlhPgTBAqCAOycsJ8CYIFPlD6Y6J51BtRFaXl1+0l/+16f9mU6B37vSDHys5cbY2qoT+kD9h/RpEV5/AN8MrpZ8Rg6wO8PDH6gBW6CN+ErnKgcPPJU/JqNQLdI0I7mgu2znmL6mVRz65NMfwbMVj7/nL+atG5z0AXiBiT/vFVnR0A/wky3//TJwP08+FT/6PswOpXQffBIROVhjTAu0UQyhT5hrPt83uqHeR0JwsxBqeHiAIx/jiYJLkVZZ/Y24tmLxyhmnPbCmvMmD61OkSK+r8/OeU+8jO1XBS7k+8oBugqLCr/3Ya9FCrp8KvOra/7w9f//GG9zymhLhYuSbw83nV/+mG8qHdoMFfVS76G0933lwRT80tcIBCBPS1CSsUWdlKwKrHZhdP+0sJ4O2fwFd9RkDge4e+Tt5QQL/gNERp+v1ZER/KRUDEvUn93jbHM6f2vsqyuudAJMx/9p7TVEm5NlqrXahGUo3j6KZ/7FQRj6+xoiR50seCGKxHw6aPmqnta5Ch2nMc6d4vKXBiwwwIW+6Np2+PCbx0hV3jmc6vf2pfGT3Ht7U/Ir7p23YOfvAwaAnHwUa9c2COx68aHYE3j1DOVb5oFcOf9JHF1pSY1DnWiLqLAKv9DPJA5ZEHtulVjozZj4BFWzqpxu2Z7TiHiU9wD8K8bSwscvqBTWLxLrgHM6RNcIK6HmTNF9bLe0Ft747yX6/GQX0lRsO+WiarEvz9lZqsp5a3pseznVmVUvthiOeHGoSNkn8Q9RRZJJixP3QuJ7CaYCJJCbx8mHXzWEc/TkFIaPsBle6d40WgC+f3DK8HNf5jHngVNfz7FFz0leKKdkUrrGEZSZT3/lJYtv6ILhpR8mvGIPMphLOvhct0jJi3bdjyIxyCf+KKS+4dxlpGsHfcJq4mJpT/3yUgoX4CKTwV+j2DB5BFqM3d4JvZb/utNNu80HrwonB5rwcK96HLPct79+6rgePjjafwwVR+hAjlKJ8c5EoaUZhze3dsbmv7a55wYICDbLj/LM0/CMfqGseZvw0H6Q2CO7/f/ECfuwxGOoy3MJkLpvTMB1+Q7HMqIf+FlbLsaxAxkMRDosMIK3nc20Cwh5Wtj/8yR/4u3Qbb4gf6S3T4oW3KaMQCa9rC17whYNNfz6dVh1eEgrePG5J1qn836QTpYqYYmNEOjbciqv7UI8lSIEfEBXnwzbTQx15dQrusLCdNzmwy+6U7reT/xC6mS8g4oRjW0IwjL5ghOBTNn3ufwFNrJJzyCGrhE43keB7wbE9aPnDOazhrFOHczyVqjDWYJQXLaSJZ318EPd9efyneJlfHRiD29lfq71gAEKyVvJPuUeu5h39KGxoW62YMuMzocMF5e96/s2RFWdFqxNZof62gt85Mx7NAlfAiCbC0vcbQG0o75AwA3QAKs4IXgP0Y0PXI4AZQx7NCKChDqkPLhC3DeVBVDYuPy8dgcCT9AUOx0UPi6o0BV0P6vo/2m9AhA6hprKgcqRRIYgS/H/4MvCjlqabfB201/OpeG41rp3Rr1O3Clu1mcub7G5dMMpNkXKMpdUymLuyqMXhM4GUnbAW6k4avtkUKvNze3TARNXwCJpvLAba7PdXEY8Kc7eMh2MbfwLxFT3tg60iApYWdXjDEMW2UZkp0RIAv46iFWol8n2VHjPOfyel8O5P/lAmR3fO69zm01R2E19R2E19R2Ep377e/s5MVFJHb39nJio6g9ZwbOcVId604ddnLhzsrERFJfMVSYLVDrHg8rVC41UhntvJLG4suXoSPrxRdliqevEjDWKOW/KJJBtB//LLqWf3CuU9E0HtepXSJAaqdIoCnrXgwCJTxffgMYrLXGSABX/EAGp2PBqbl8IZiUZ58pnHnO/h+RXxU+T2A9f06ur5uNn0rsq/Z8MjlI9Mo+29T56ZLnf/YgCEGXPca4ATckZs/BGrFW6g/gn9invIoxcsmfU/VOfkd4MFnt2iIh40O8+/AeLYiQfnOeWy508zhy2zld+MOgTIfe3w7v5kASnYxjb/JcZyQ9XG1+5jg/6GD/vSozREVY1LRrw3sZh92YJHxVJ5dlb+OoKV1jLtw5Ve0Rvcx5vH4esJ1y/+YPstRfXkQoGwo/DTfs2uHO8UWuVm2fGcxzV7T9A+M37lyVDmZCaAbfpgG6bkgJN9HI29Xe8ogn1QYEIJPjB8dVslBUUu7AlT6+gk4Uk5K2KNGR6Kgz//170C413GfYfTbAMjSjN48znstn87Vteom2lKXggoT1lvAKCUJYXIwTTGmytER3wjIseH10mtGLQpE911bClC5gQ5XrKZol5w4Ec6R/cyJ9UbuKSOsXXjk1dMgwN1nJJcAPO6sGP61dgvcCDOhd1DNur8XfgBGIIqGTwf5RXhRQd8cAh6Tul4/rO8f0v/nrxvxdVi03k+wi4oeRBRrW962MX6WbA/bf/myH9//kZmz+aXVgU4vSnnlgYOTgQSP+KZ3ypis5wr6sRSGm+f9dD76+3DR/uG11w5zfs/aBoBq47qgLS9B7Tanrm3o5cdvl1fT1XnB6P+7cT6Q7IZifs2B7Y5hhv6lqToPxuCt7nQu/7eZgq3t577P2PQ0a+cdy+P7Izfeko8H13xOvx0790DmE5GH4+NQa/qbCgurNsP/Iz+lRxFQhQz7XWWXQFpwR9tflwAcqpbp7VocxRP3KjlUYZbv/+ElNyY7MhvjyO8BlSJj9EqxedPZJkDxU4w/+7e9t9TVgjdMCdisXT80eONkqq4XrSIk+grvVOmJs90VcypwnmyU+1+0h6f9TaS3EiMm/x3hNxJaBYMy4CEyZ+uh4ye5QH/uPsNElIhblHtCisdEVhTMjobUf3/NNPKRWs6NjhUJa3jwhrs7HZFmasMYcFhiP8Ks7HfOY1Uub+V3+HpJIVSBXx/7H7jJ/3u69wV6f4+Ptb6t+9COABUyPxE3/B5/6bFV2IC6gf/iAnVBJmJVhdnpnzAUQyjjd4AWLr2sr49b/dMsncVXoHTCWMwZ5PCtDivHfOvhIz6f3KOBWoqED3/GS/+5Uago5+oS3SmX+d/7LbYRfq+c3L/CLDJRjbwSPfC1j2nWoI0EHVfbUG+fNG/eJLNAscmqMUkn2jj3zmFDT1ftVOLqPfz1UlVi0PiH+HvdMcvx9zUnfnB63yRivm68QLY38DkL+OfClRyUoC/DzoW1+PmIODWMjxUFxH9RDlE0W7ghxL8UJSC+CHEoi5rkB5qtm7wPiew88fb8fHrgAmesb8fUKs58o3+SQqYmJTiGutwQE6td8ctyf+5f7O6tTqJffdt1n3xAxcjYXLn6EvMv0GxW442e0yXzoR+URQ4xuzB3Sl/E17Y35uDjeX2Qq9Mjg5y+LajH6PJL1wj/PNvlYGY0173Otf9oWhnbVpBI6hzdoLfQk7dkkelD1XGQ682gD8g0byx/iogqH32NzcVkemP6G75VH49cE8SB7MDLMHfX7SP2daQTdICkNQAwuPFalBGW55Bk8Hr6A+bRmrrhqtP93KJtnpy1150dFRqxHymE8UYJvuLnqK409QJHUpvUlhZQx+tb8nXBMSrP3b7tCOiO8q/g8CxfcdILX/uGItpZO2vkhDrhxwrMjb5bONyWN3cXIreivkA+uu9PnM11L3bLdT6coinIacY5V2ilThmuQApqj/8xS7+KOOn/9XJDKIPXG8T3CGocyK7hgx5Xe4ykb51KuB4saQImK/L2Ew8NX3/PYMGnEoXUU8B9mN8SCHd5iNIXQsPeQ41DEV/+k5//wu+05bNEi48N5y/6JqutqJWefO2OcFdiEku5wx7+5cx5j9s0GP8zMeRPrOGd696X3tagweGqg4H2fFn8fL2aRJ8FaMXkPl5NPVV2CAx3eIAx3Yfb0NpS5OtVSAmb7jGsgVhMXhUs6EyOZNjTX/i6fodhmESdeToSO/YFhg/8kJzqar0ni5vGUELYqPMWrt9BmJHIJeC/E5RQJI7IIECinahjRa8ommhEOX+qZ8mgotSJFUCGx1V04wH32n3ij8CgW1TtNTUmROg1XrNwzpWdNelc+W/NPA/IllNwOKM+nK8iiQgXQhDjL+Un+ElfE9f/5hsZIey5nLyu2Kalduf/+mHM/UmifbFLX/YcsQh9PhyaCX2mwqMQ3xDwkzPnNchuU/+Fc/CRPa32T55TY/UiGl7rYfkRJ7PPVXgZY64BIo5hkstXZfvcnyVG8/NzTXpAjiV0tVZFU4lvOnA9UYvdTlN73ffqBQ7jiW6sFqoG1lXeV26Au5rh9NEpzDPtTXTenGDLsb+TEZIlH5NYIkz//6bbH5shrcMj14b89JSjGB3Hgoo2KEl47lrT8hY7M7CsSiRi2QzpUUw43yyih5Zq/OLH4owGXKzDOpmv9FMljotkKwpNSKZPFayqc73lcVE0tayKIGxAqcx/mckoNX2Mz77gy7MDiqGzi4r6hEvNsIMMW17R6vy+9k/puN53NOvneoWOuNm5siWaTXr69DH8JwhjtTgjn+wOPgv0bnjbrXhrr5EVGl2hQmfln8xP62YHijl6ybXx7P04PEoBHRTH5+E50YxeQq6P+hvP1QXY51auzr+H/rMIMNBDz0ok/+MHTjxm6/PtrS3x448f+/hjJ4VeaDdl506knv/yun/dmC2C4hjIg+VajWkOaAzF7exFAXcq0H9HhbwnO8uFThwgHFW3Xm2shZTOX9fNeAyXj7o2e83mb1GbMHIiW/9hVq8Ebd7TY90G7Nz6vkB/AvTTtW3R7+Rmrjf/JtS/NI7ySSoY0YFagzmykv7mGaOdZuIAdIy4S/wFz0k0KJ59t6GYMzMHFQN18tVRNHmZJ+y5jTBsBcJtdti5p4b+sBSRofj6/4mP0p9k2ypWvxMXW/slMH/iX0qTf7sIwE31aB+VlZ4LLuHqlkSDCIvLERLiUAVzkVCfG2bIttzXZrt1e1K8Phz26fUvHaGCfa/vrj5/06W3mLpcP/KqWZblsy13p2z45t02GLvmItSE0q72RuNR0I/rEa6Ku3sOcj3NfNgGsIX4m6n+gX//lRpuBgQGQLPwC1bnOLk34xWI6GWh2pc16BTDemOJgbQKGfvl/6u63prsq/Sr7PNCccVUjaQRmNT/+H2KvPCJRoPgdn0kECOdhrEuIk3M0CoStv2fX6uLbkKIN2QlN86e/v/tjHiEdw1qYKgHobuB51awR5AaqSKnNTY6mYVY6bD38BqvY3t/cMg7oV9ITsZ2dQe0SIVfRxI13SH7FsyGp+2eaS8yRE2Gfxt0K5+Bn0bK6tVMBvueUjysgTdPhGdl7kO+ItWIwPe/M1PkTliYROj//vSX7q1/gbP165ti+n/4HxHE3/UffOItZzzSemEKuJdnA+plQB2JvQKaakzkNSkU22CiDiOd54mIQ/EPlm3H2BaTa4xhHrbsMuQn8Gu9jpbOoX2mgfP/5LZRqTqdJVXWSUDVHD3KfuTSKQJbxLlEfd+psT2RrnvKeOeAAlfIgAabEWEhi7jgpMurypYXAHBpHx8Lw3MBT/U2j1hv6yX57KNqsbNuClvNAZsi20hMf/lhMGzn6sVagvD1kAFyuT0bXgPC00R7VVKPWzlkP4ZX38lVj0Efqzj6vBCCbTOv5/rKZ/UzlMjWex7++M3xby4FPG0iirE8iOFOKQL6QPhNc/sur6Mnkd98L1HpPaTUsyeh6NilocdvVAhkPD6n9T5WvzY3/fIfPY+3QlT3dWHoRvzHfcUCRThQxGt0WVYB+PHVRFmNx67ar2oK4rAhkIoG//K9tqpGUv6SfkFmczmJQhYesp/1Ia1HiEWPza5XhSs1fxwt0NU44cBGbpsduoc369/eDzkf5/4yX29/T+9HnvsThzQeCqcQeqA7U9AFjpn4YBAwowCBtsJ/h3V37+tvR/YRf+Ht0vmEFh5v0BkBEqLfA+otEFRl55kCH/+a7HHqERazueCyo8tfwj6ex7BQCgX+YubcczC3etOHSxc5xT7Uki+YmCxUTmWBArb6VR4JakKKpUJFdWozUdctRIttceHnKPfDWnMaiMGlrIA63H4pa1iglyzrq3T2op9zgz5Mf8eInvEbqJDUfc2E/EiL/ph+H4s2BXEcB1fvzYO6Qv0eyisLPum5H8P/HJxL/jw3+Jt+7l+P+txX29/R9sPHw3FWkvaKnEGW38+7bF45NatK3ANZWuAee2s/AbjvAyGyhuKtf/lxLwjd3IkUeo3RKZaoH1Bjz7ZlELaB1C9TKxNDNBFb9WOEGVqMRmV9/6f9PuwjLbikjzWvfr8TmE2Jw6WLnOKVzef5n0ALagl7JJAya4BrK1wD0HWP/xZl4g1mwyEXvJsfLwISRrhvGNVw3jGq4bxS08l6WWH/Bx+DZ38HIFvW4BjFAQNPmnvFBlXCVd3g9d5YX7eWgZqGJdTQoO/74/CTr/8nFlq1cbpZmuDvNhCcF86ZsXJFZ9CceeD0eYt9QfKBZsBZsA1mCEBuEnoiFr+szmy6diovHHNL0kGbIIa3qgovAzv3cy511AoCLqhCz7UHxX2J0pKUflLIxQX2lsyEQkzWSvFbyOfKwuGeOLKvkfmSoaZCIIYxZZgfzQHRNnJWcc0dqTOxXM/94Kd6biCDGuqQfFNIy+x/C9xl6/54ky1KVR4JU+utT/vdaCaTeujc3kyfeCzlNTfNtHuO3cFkSKNsw8zJIkXkiWOCmruEWLwz9qh/8FK+oxuhXXy/J8GXfJDgIaZImIfyTDx0x4/goCO8XJAcB8YgpV1AJMrgwMO4pq+U0n5UCy0HbfvdLujDysqxaiC6m4ZijiPa4Xmav4y0ZPIMrf/e7WSoQmlUnHmPIuh1nMRrSLUACtxkqWk/4GK+fL+1XQA8EgHgkA8EgJW3N//gzgEJMBBHcGcva4KYwrRfajLN9sZ4u9HDehd6DFoCyvuUMuRmyux2uBBln1Z6kiviTdBuXUIM0XxgNO5FFlCtSBpvrFwVqvkLgVZ91UPe4AamJVWYXSnUDxWUMnG5sxrA3HuzR4bu8NJ1uXlmua9XTJaEjcdIaGiI/plsrTsZpyihmgSENxpOnMSclhRJHz0baYo6plYT7iQk5fVW51e+Brt9LZIhqxsYM+Z51tbHQ7Fsl0XZYlesF/H9b40b/jifwg/qH23/LmQwP17PIRR7ejVE7dvNmUmXyCuddbU521syWVF6fQBS32fQy59+Tcn7q0SMKdqQ2flUo7ivmpRF4f5KAZOf5D4K/Pvw/Oq886YdOi3JZdiJLaRAfmT4Dlaop/xkD/SxZTehfCv9kCHFiBk+GXzslpqhAHogLPsHcSPGR9DA+q7CghD5rCXLY/blsfty2P25bH93/CqZ77lLhvDnsLVfCmXZbiKYzwl0eBnsAiz+YVPQA2bB3jNnRHgF5z84+G8nSGJreKD3fCfrnIewBHDh7zchVv8Tsz+oXpyluR4stVEodTI3F3RXWzMnIe1ESpr3lF2qwpqDeY3CnwbytgXLfdtZrY3zNMOpOakD718mOoBd5eHsfd/5EPRWMFaLAYBArpGiYBnv4QCu29HPOj3Ak8ZCAtoOZPlrq0MkloODgCWLOSMgeAr0VxwTjpHfmQ+sY1fiZkv/yXFs7gqY+TBPRb+gI23UHu6iSvUHkEVybkhsMHKvz/AH7vNIUC8WLtueTTI2JlDm2DDwmvdm/oWVHUjcZ3dDJqvBzHTE2PK+nN0hGnJg4emK4Z6wuAdO30kdxqcnToyBpYMHNLK6lGdPf4AWZUy1B4POVP/fyP2quW4YSeuX/OQTjInocj9PP9tXPB8JVoXBdP/86T1gG5IW+xvTokJg5Sj1HTXYLyxELwuXR8oOyORXaYM2KnhVBU4XwEG58vx2c2x9MlALt93HFGduNlqzwENuUd1WWk6jPCb7GXcVvlg0lw7N5uaH/6B4v9JVTkpB2Y11lA4obqPG5oOtToBRuCtaFDEJ5eK3+v/NXg2b9M9s0ACLFvAvKLeA0l0Nvomt6kF7EOqQKcSKmb13Fs2BZj//raLXTDfYUL24JrFEES+Oppmf7j/h+7vOJ7vd+8ZbIWTAwXauN8e9hl3u2qXIjxViPNPnV+PW9Cwj6u7k1kORHgnD8Z9/Oo2t6cq5pUVJx3Jiw1wgKrQGnhLsx3/rPAF/4mqbTfAL5Z/JliwiKWx0hK4s8SGVzx9kaxPGPWleIHDszI0UPINfWlfzKyBOMMh9EOM95bNyX9vx7VMdTzpLr1Oae1o4Qi/85Wxg99yQIjM1HipCmVbuR4qxyCTzC0ALxFkZmUSqKWlQZ4F4h2okfoaZNwp59X1c/+bfIa6v4OhzShEoU8w2T3auL99G2OXZDev0j7r/+P+PXAPd3bP9P+f/x/z/xd3IybLBBnVf4L9P7jP8RBUrVHiBgc5hKwJ+PTb4mzMYxJxtA7MQI5R52YDRNI+i6003/i+az8iFmzI4sUTM4IQqfkO7mefaF+6FRlMVKQJHoMpbMLDgQRPH1zLvLA2WeNRw6/JwfOeddN32pf3G4fcqOf3qewjIQZppj//ualIj/zSzEt/8fmjb8SLmvhmFDYsztRhTPBB7V83CTLcTiwtL9CKCsH6zEPuJnPeoWl6ePrQm5xBjTPgavZAi3nPeqGsbDMva+4PffHX3tp+TmWVHNXAdSUZ591bxJhmccmT/7xENQ74qxWtOPKOMuXM2glAKnjT70PHW9asrs//zRkUpF/V+yoGL+aKn1UsVrh9q4x+ceU06/8lp4ebuL/aid7zEOmkOOKYU4g49YDrcefP6wzytC8kbTfxFJ2WNwX81REieRqmbC4cxxKXQOlYwEGj/tZy7NH0GaGVgGvZW3S6KI3tBtSh8tnCLP66cOtGy/rIc+haeVaPW8T0Q/LFjw6VlZAecXw5H0xX8GY8uljD9DWpx2bKsBgMnN/Cgcec97M6dWm/Rq9gQ9rPylauGiT2Hfh34d+IHV65jAMQXtOeLp6XAL7wO6U+jJ2YJttAX1R8cHuepwaVkshigxfzE0ycah1/iSM4YFoY//K9u/pKO/vpdW8tXdJlz+z4jyLfMpd6UYAFxMZViValveIRGibeayMPM4jUIlb4YVGKhCs6m/rCcB3kcrJz3dLbtVMJgpIg00V3mywF8vQez9gXhLmJ/pHQmeBvWWdXGdFY7Tu9x/IP1aBrxEnFcqIPoZi4hVQ/JwTq4f0/xZfojIjwq7z+wQHoTOMU9x24fh8IDsGe8my/HYLIsNTgt3nZjtzJ48qf/RLnnXQ312rr9fcCxiflhTuw4fUogLh0cU+Clh6pBzoHHtQK+j17xZ/zi0yd8DWSU/4tgLw3YIxWf2CAVlJz4Aj8GyO42r2mHOo9MK9Al6O/pBSb4IVwnwdvps0NG7pT6MnZgm20BfVHxwe56nBpWSyGKDF/MTTJxqHX+JIzhgWhjxtVH6Sjv76XVvLV3SZcRKc61vLhjHPRABcTGVYlWpb3iERom3msjDzOI1CJW+GFRioQrOpv6wnAd5HKyc93S27VTCYKSINNFd5ssBfL0Hs/YF4S5if6R0Jngb1lnVxnRWO07vcfyD9Wga8RJxWfDGXYcJ4jeeanBZnQL/iy/RGRHedQjzuTbKao2SX9fD8PhAhXj/9p1//1EWHBtk6fgo9HpM7492HjNpFg5Q10TQz/5MWGelFlqo02TyUeIh0jrqDRgeLyKJZfq7BkBG0/Q75ThxJ4XnkvkjIyZX0+8WdwuPLnTTJ2vtqWczsFX3ubzoa8lul6qy08QZJZd6etTAzJIf7xuIYbP4tgQ+tFSjfUXlJ5Lrv7A9cwJaFNfbfkIWa1RNlXXMkJfsBFHM7JcmKETjP+/o1IjwFVG4uo3jA8xDb6K9EoODr+FMJOXHfaklsssW/ijPmReoBXVF6lIVRkXmRunvabvxsf/+RTNBqEZKogcFCdIyVRA4KE4EEQ2ZUyGZpnp1hubEhWI/ncZYneycgdz/pmn2c8+QH2l2ZmytPMKu+wuaDG7v/0UEkjOoTuNgDxBee9zJlAfH2NSkRSVCMSvJ4SoNQzFyBFcSo20jlVDl+zmTGzWqcxLeZ1w1n0aUd/s0QxO+TXppKvBXE1xFCcIEkuKXqOP1oSWbbrd5sAw4XYWubM9ADKrGC6xRKcrBchDzK08K3qABfaYcqZyyysVmZK/oPLtANT767mjM8Sql1AboNqq50NcCoF0nQuFtH/cTk6Fx8ToXRi3Bs3J0LvTm2h///vLTEnkDky2N7gWf5Ol3IZiGfNPFpZOszwvHfIKJ8FwdjR9GsdI/uT8cy6dNgTOymKPtvf3Ar+7PM13uuM84R18zv1VOZ1phWL+FjlcFQ95QGq/aFb1KiOsyHD9DKfeuEfK8kbSHkSz/lOI3TIT2hR+3PhkaqYiUYiaXksjE1ehuD+3Uwri+YpeYQrVcjj//wgCBxO315nqfcSSAiYY2fvn97OoJ/RedtU4YNOiVam2OkNgoIDJ+zfgZS+esKI8WCTa2wo+MzVwE/+AFcpCf24w3WuyKWUNwsQui+cT0Tf8+MM++YIejszfnDdemrvELsF6nopeu8ae6wu2nbPMN/eZ/aih6WCpE2LFRh5W/sP+gIOTguhMgQtdElG/8ux9bA/K7YUCV4SKsPRo7HI3PydzmCv5bxjL8nJ++Cy3W5Ezjy/2fuXD23mKxJx2mTypPRVMzeTcp6s4xxYgv0Ka8d4I5tgf//dxU/kUmHrdf/8l//+GAdH1UEzih+GUMzKNJ48hWbb0rX79PIvevrPC5zF9FB1v4MyfhggyJ4X3TRxb81McqSqkZ3eSPvfDCVIhg9S4dtluWV04wLj7i8gyd+5DnE2j0BllVtXLHOT39fbYRqcki/XK/XbE0Wosoure3WgX52uQkis7h66jDJ/2JZX/5Ieq8vlQc0pSw2nm7/j8Fn1of+HLkZlmnO8L37tY0pWEnP3q9GyBwOUgniabMgCCSX9uZy9+U1aTf8+9wqSIeFjth04WY11YOv7DOWqa5/I48rcIVRKGXeiF9BjRfiS8svHi5zAcy5N6FEyYfwFENJGt8L4IPtesfhK+Z2GcWdxnQo6uyJPT5ozrN/EqtpcSpTGOpNUEM56ostciNCC9Ux09XJ4xHwiLHjHWg1ZGEQyl5u9paelROumCxq8/lOkAs4Yd+DlJScEuF0GWm04LmFoAgLbQJTIt6+Ubdf3BKx9cbXItPgP+DUB4j1hJ6+kSfr0Y+dHSa/5uqBRgzZgzrAKYZ3lYh7Deb7/eO0v80fTmnVr22EDTz4hexbv5ZKzh9u2fvgcVDgM8JNldSJUom+LZd+W7N/q+wZi9+Wt35endcVCK3Tb0WYDpvlvHiykkbkHXQM5sVXWc4DH6fWjKdLQ1H/A1O+/3/bp7GHzX034SlQogrGkgI9Y8ywKT4dh+Bl+1//H/Prf/L2Zj/P+/j/j/j+qRJPibBR5RwG1e0BNdc55/qjE5EAe7n98zG9ZlR4f9IfqYY1RLylp3vccabS9b1OwYRKGQ5n//jLfQm/0f/BO9vHavxPxwar/DC23rEoz2kOmCG1PuPT7gMt8pnJVlcgHDAib69ZLod6pKHllgBHcZB2ImElT96LaRSGghh1GV9gpckPY9DPSDbnrxYhCzosPJUqGjzbjLhGA144NW+2FrwbBE9FEGY3mZgWSyfhG2MFFz2Z8SR1VystYIuN5hVNPse9f8TeVfqgfcoI7W/0HrRcoIHY96bN2Ne/XDEpXamkk5ZHngQHEyu+Av7k5jOYTDvjePmDYhXrE15S9XjWnBjXxpd1rioVKizNYEjP87Df1GGh/9r0ff0xtu//LLUKczXRSiFBvJt8qNBacDwqEqNEouezPiSOquVlrBFxvMKpp9jtgGNwNs+t+dMqOuFLXMWw0D7Bf4d4wQGkR4gQFvynVR+3P48uWvdE5a2rXAxdZI0QlG8xec7eO4DUctkbYBPbIGg7Qot7/hRQVg0qw4xtf6RhzZvTxoBVKZ++5kGM7AVhFMAiUJmET3ee5MGfbiGQwdmBH/nCQphpJ8jXsBA17AQNewDl1ilA/+UO4oG69lv4n9M7wo70j0e8XaHyTD/8/qIrS/eg6O38hF9k+2Ylg4INkgzBjtPJmhH9+ksLQBWyyyNes+Sg9L0tp0/HjzXtChmCvOf7dPiruH7zOB3hX3YfP52uHv8h8SeiKJHsM1J8bE7bq+U9U1Bb1jf2YpraOJhxwy7pTgOBDLhpV6wMRXLUZbhFrikfpZ0WxNucWyJZPakBdq9eHFnRxPbFCFe5m4JUQ0LEJq2fHV08F6kp9jVSU7j0cc3/QLjZVo/W1wUmLbr6jnmiKdbzh1Rkv2ozKk9SrDGCH3J+UsfABVaQK0boRcPPHDjo8/epCsxXa5bR4FCtIjiNYoyENNi6CKJMCBjXyTsAMrMOKT0C8Mxf44K4ow/G0ZwmK4dG0wRlKMFGHC085mfOLDcV7PhwVme7GnaiqMgkOswuGJIjCIOnWYyCdoAlcAVQ/JwsdIJp9WOKmzDi7XnosFlPkATbmMsUuCEsRMNvPxfDBtGXgVOAzycgCwn2f2itWmnsawUrHsy3MblVRDiDxwxsDRfVmRNaMlXN63eiUXlz7HOHwDKLZYjBJB9qx2xbSPpy/jtJDrf8lu1jiVZ22NWMCJ3glfe9BA8QKe1e99kjFkI3F4gBAeMB//zEAhr8PRzbUyhNJ2hd94N0tWOnDigfE2pQ5rnLrlHCsCpl77uGVvwK7qnd/k/JiKtXLdKFK+tV8KAIBk6Q5KcAK8H8/cpnv7QZhvIB/L6AIC5/UzF9J2I9KUbMMDtgmfCSDZs39LnCoCSxyJcWKprWmzt2htEvX92eJ5wv0/n0x/73Y2lLBKzi4NCAZ9dZFxcH9DTvjEOsa8//FhnfZaW3c/dz/kmzztDJKvOV8oziFo58G9D2F1rVRXU4OKukFlBwzNSI9OQ8uwPFlQsBOzRlTSEa0B9RSCJ2HV/3gPxO97ZfYOD/x4SI3xzgo3L+P99RxMJBgwGK7RBbLcwom1FgYrFkDzntOc2FGu6T9cU2MpjGz+/tv7ddc+QRMd35wvxNldOLZETZrpgtwltoEPzRxThtJftomSy6BFGGiWINoEu0N8hES3YWKLF2uHjHVVXrlvPzRnSkQuNL+pcGzjs3gQ9LcRzkWfIlLI90+ZuAkM0nzo1k/k9x51lYTcid+rnglOu5c8hLqaiRo61ngMfczU/YAiBvJfQjnkM7HVc2xJmdfbyrAcY6JoSh25VcDmqAf0dnVFLMjEePxgx5Fryvas/mC71HXvbYrcFOaoMZNlV/si8TX/TZcmf4P2DvnR25tHTvinouSWHwRqdT0oamzViKlpz3DuiPv/8D2yXT2FBvwqQP8NjxBjMRYhjfF6PgeqfCrBMU/DVL0fA9pd0+jQXoOEtekPtgAFWixZIY76n6jPMf3TW0yZ2mK+4Sc17wnp9iU6xgKGbcYr4RRDqK4iHsn37y7id30mmD+Lln6Iv4DIak2Gqy98nAy0SRoKG/Xfn0avXmwPssf7ngrHXXiG/6Gti7h8qVKP9sugRRholhEAoOYByZyBir8JFVEGr04OLL1/LPECZHv9hGic76fw19Rblv/5JY+ux9+b5dsNsA8en/4JeYfcSien+ku/58m+AFQ8kCQAOXZhf/pOl5JnJ/F0Kys3rmY1LXGk19K7azpk2jK5cy7dU8kdq5kviOul1c/xbFy/4FeWd5+d60ztiu/gbqv0pjOhJ6d2dxECbMN137//A+NeIQh/mD/qJm9SmZvcGtnx/o3g6J9IS5ZxBq1dXq895iJXaxeH2ARd1vGAHAj/2beLL90oq7JSEtPWEN3B8Jxk9yJYy0e54WQNhBcWd5+duN3mnMQdJ19L6/4i5IBKtr4//IftG458Hto9zc/yYD1MtaWpZfxJ6pegFfBMf8ePogc4r/9gC90pa9rfLWc48z3cvsrWR4O10G/9JOlZD4z5BHQfLzynPS6BsIjRE2ITz/JbwdwEVF7X+7hn7VXwfFHHmATN2ExUlkTGa0++FopZ7W/zJG7eGwEzmyzD6CpLMd812Pr7TLBQdDlgBn8y9u9F7J0xH4KQ0tfcVlLMcRaiPtrl06IPAK8da0jQ2kr32cGFr4HZBQKA1HpFJZdOvDwCvHWvSddZZN7ojAPuCT8GRaV/PLzeL7drf9YWj1y3TELcRkGuubQRI98wxWyUyZG+IDBT64eG5q82PBId84mdJR0HegRIsIcQIs+kggr6EYGWKs/MB6fZuGtpLP2AFCD8ZXuO3j19uPdKOdz/w7L8ZIpD9+d2VNeONkjDf594/9CfLSyrgPciEXyMPy9bvptA8OjC2YYM9hCvuRCEsGxGZXt8kUNHvZVb9toNoIKKNFR93y28GuxBYrkJ9ScrR5EnK0lcKln/Pubst2vf8/37drYdAIidgMqmYRSRhfv+DYk8NTgkUBLBrBd1m2qhPCkyNW5ZoGcg/9JPpWso7v+dgmNFEF3CBUk8hU/+i05LE/soK6PIaKv8hpvtC30TdWS6q0/7p/9v2BHZ97eEdUH7ZG/T3zAV9k5k3F/L8M5xvcevGl+6psodjRCkP7lyYKuIz9aRXEA2qTCuDt12XE0Qed0PARx9w5q9OIVZ7iheP/6o5mMnHqUJmPoZ/Ant7AGzSL/+JgXv90bnVb0BEksrjSUNt4n8IcniMf/2T0tyMTH//zx9XPEsjmcTI9ZMW3Zu+jTqeZD6wlNGeJgyvf5X7N0c0X/kpeZJnvk3G9kV8ZJs+48YAPsI2pxDdSSAMgrgvreXPGDZzhwurYj1p13Ipd8tZ0ChPRLBxXI4F9+qQPO/scWAELWP29n4ZFFZuwBLZOCX7V/xMbFTdMZj9u/99YfzLeXtu2ALy4wHqFeV7D2fuCbX3bF3T/+2x6mU93BGv/9t0ceqsELnxNNhTM9h7oZ4r+BcFKBghGUMChCMcRjGWwkJJLRJomrWP/OPQaBnFyn76/3VmZbTyUKDp1uPFBmK60MjpcV5J2uIOHTYwa2BkWNGUJS0sHLb+b71duV4XM027BkSYguRfQpEMzv8U+9PJmc3/xdUpv6K1EkqUofGpAlUCRsM7DFzirzBkGjya17FP4cyDqdSMcU/9tPhq2cDtZZX4sF/6VAj6xZEKQNk1aFJXC59scotg8aDhWy2sJPIeObkY0rZ3xW8ifpny2fQhG8jh1qF2FOOVro7bGxejCGi7tV/9n/1879j7a8kv+FnyKHozQNG+LxKgBigBigBQWxRSJ2CjYjcZTEuwBECgLw+M52gtQmDFgRdHvCVYAH4gnYsYxJSEkiCQbU5wfCUOa3/9210OJbPynFx152+TEDGn984fXMycsm3if8HJiZQ6cRfqm+DT13FiM7xzZe6rX5WXCUARUAKW76ywNorGYSiH37rojq85IhBZ0PZAnkAbByRY+P1JyIIgOWas/apYZHY20P3UEhcVqg14oERbJ+xND2pM/j1HZMTyAEkYBvZ74HsI3PA6Nj8gFqf+9j0Douhv9Xxrcd6z5e6Ute1vlrOgLg5ALFrn6PLLKMU0u/sgvEFZPDKvKWgCsy6CI/FrxOELuWTiaVt6iVqV6cZ3sEEp6ON7yhMLjHRoIaU3WI4OxHMXYxL/dlPqYFS6cPoC/CyvPDHxTsxNYvFi3VAI+X4AyWD7G1cobvLnrXeJnS/PGHhZVrfSHBcWGPjz/H6Dq8ix65q5Lxdp0H+3l3Oy26tPkSyep5M6lEshl+o689WUneU4qOEKp0u4fbigRNsHQ379mPLLpWQDwLeZv/oJsw7rHMiXbzKnHOATvqfd3ulKrNE69wv328MA70KFIX4Gr2QnbJ1ZtcFwzq+hW+3yJGGWAGykgN2nU22g4uT/Iv2ckp4uffrfCNaWbIHCc3nen48Da9OsjRojA8GNGW3H47zFVF/rgR/8XmSKLkGZprq+fsDih2t8nFfnZJ1fn5ENpFId3dNlv5ssX9cTDkz85ACkA26Tjh+zPlC/Ufu8FzgWXHfnrR78U7YcZ7lT3/gh6srP0gDvuLP/xeSA37/BLM5IlvdKWva3y1nOPM93L7bCYrIfGfII6D5eeVO7VG+HNc3lE7BnX+NVldFOvpsi/N8uwo2Q3+M9dk8o+j9MbMPz/JvNVoYIQZO/bzei0JpO7J+qshyEAfGOjQRL3NnUcXvIdCS6ny7slWYSteY7vLq/H3ptBj4qCGkXRYAWmHAXo+AO/F9KYW9h57JDDY9Iy5xmV5xXq5ZyZ+e1O0G51T1udDr+Jg8RB5o/zHnSu+XJ3u7pWFIXeX8eCVA6A+z6U5deINWrpcr6LWry13Dw8h8lDTwPbCBXvCxaz/Hj//PikzjOKbub+rVjFXjakjKqrmWw3pVvYhNqiXIWcjYIVhTV6TfO5uYn64biLXvVtkOLeIPuwAH68QBua3ymgj2Np7LQ/E/LU8/14+AuhJN4VIsGSP2PM9+d5mlqg3ig4Ak9UvQCvgmP+PH0QOcV/+wBe6Ute1vlrOceZ7uX2VrI8Ha6Df+knSsh8Z8gjoPl55TnpdA2ERoibEJ5/kt4O4CKi9r/dwz9qr4PijjzAJm7CYqSyJViT48/0M1F6o/r0Hi6y/G4rIuUK+z+oiVqE1Ffp+EFqr5TGtEYx0aCGlN1iOL3kKp0u4fbigRNsHQ4JfIMq6FleeGPinZiaxeKFw/+gmzDq6efAHfe6Uqs0Tr3C/fbwwDvQn3VecV6uWNkWR+9m5tHftea1SoEm5JvDzjzo18fXNVmjz5F+zi2Uy0dfmgrqd6NZ3bBN1egpY0AqaWkg6XfgL0B8hirP0/hsdFnrg/omUAnv/TJuia4g7/pjnQ2WAO8Pb4VdjQHePq5RGCp7kk97ZEeHPhDoLKVkfDgNLtHKfLBGNax+VxVIBwEX11oK48HHr0ZrOk0xOSTcKmJGa45U9Le5JnprwTjtfqX6u2SPn4B+XOsqM3F2z7VjV0g8yDOfI1ygST6wjsXeI5jXKkOaFuqjejEb4Hz7xXMjunaYYfXU4Nc+oI6xfXzhfjK5VYk2lmTmvR3Sk0nX5KC6NGWpNT154c7ZmpfWSdEivpGYoGVDFmrBPpvbR3rH1xfxfHmGzQw/8PdvDSvkOKLYcPAXPf89fqKmV5dxd9IgnHClrtA5RgGECnpkQqk8EFJ/tfrqORKFYcyNoYjYkC1kUs/Fw9CW7iFLuTXOAGphizwVUemsMsvofpro4m49yrr89AJLjIQi3X/EyqUfR/UGt9Bn0OGOH0i2suCRXiR+6nak1M1+5nD36vs6Nh4X9moI+ebcUM/Men4JGfgWaZM/oGeP+0pnNKZzZ63/tRFBsmqj482maMiFxLSZsjG0QuPtVpXdbeahSul/CdsmpZ4q67ZwXvMncbSZmcGufFAMMzGtrzABId4QHgY5i/t1UNpvYQNfu0JpXQee8Mj0cJLTMY//socdx2H+20nT703CJtudJUco51/WOE8t1Zs4v1XM/8ieqLwM2TeLP/6SAgLItRKsg6/yYwqNNIbKxzbhJ/DKogN/iGirVxdaJUi68OteHFxneMr8I9YnnH/OJzX7WXxLmrZOI4kzHnoIETpr6ETpxxH8LFvuyXHs1rF1CpbSZFpStE45dr5FAvnSN4NtpnLooqmBPZD2ES65Eee29Ks1UrPm4O+jZSmH/6dEVTkxH9eJrOh2XpOf4JGibo+JvWwdViiKFw4XVSuhn4I1A18Fnu9HdC1KN445nLIwqfeZaQ7ElznSIQMKoLLxw/MwdFDaQzKQZ//FL7BXnhl9OWDbLqzTf+tuDw1vjnNERC9tXXdihLEfO00L//2dEKZO3cRUDnCnpag9n99jnVQOcN9qZ6L3oA0yn3b+TU0CeS///hct/8qH/RH/+UiesFAK0CxoGBgWFMz4hCOSDaW7iKgc+OiOp4vhm5Zxfdv8AbdQ/yOLxBH6tJvnrz/5X32Ji0uhLDPkqwQPtIRilklLOy6ny+Zn8XJft/s3X3AiFw28e+0vpFy3kHxNrVukuU0/X4d6eljIPc/X2AGmuLFTHozlnaPzWyKzC+yj2XX7kJjBep/sZ55O/EUKX2pVjI/y7d932//ulF4vi6Rgap7qM+H3vi+dKH/sBZn/+eDHDb+xtamydjBB47rHzP/XpoMdHQ9ftKty+jEOAVN90UF4TiZ+ylUYFA/MgWcSU9+VrY/y5t2qbBePA3KOGUkAoLPyVl8oDUH2Rcy0hY67ZYhbNR+cYi4X+Zi2pobOnM5B19VXfobWYhfFNzPSSMNWgW3XRS/yj0iWqcYUlpif9hn4Nd3jt5El17nFwc7Fg9lvUpy0aw4d4XM5XT/dXgyCBfzP+PlzgS8hLHi6KlV/ckuswuyInIPQdxGDoap5ocQ8errATH4UT/YAv/Zf5lmG/WhJJRKph4196DWpEoGfulb6EJ3/wYS1rNLvOwDuJrUs9j9Bs8ru9z+Bfxy+tw8NaZb5rn51uFMpLtpoCu0TgBBgTDzuNoilI9/z5wtH4o38vgoftoiUtNrkV34TW+DbO1QO9P3qLiRfhQ756oPDjD+NkpPeinVV/dS5KhXuU+d6cllQn9Vsn7EVmXQbeAbfQN0JvuVoFU6WXk5t9n+gOCZsEqCbTevFkQNOtCPCSpPKc/5CFLALvs5YEm/5ZDf0svrnYHIQUKp0kVmYe9bFcGDZiJP1Po3qz51JQ35Y7I/wHL8gRh4CkFSO33w/w303zhM2ROUX+Q5cDRXqrl1goM4Qldi5i8QyScTjbAaJyzFRK7QHSN+kqAo3/w8oZlbf+gfrA5mDZXcD/p//uzP/5X23QghzS4BWgVmEsBNuKJ/Ut5cOlVMyM4C7pU9GeqmeqmeqmeqmeqmeqmeqmeqqHU0odV5+gO69G+4qX/Mm2+o4LNIcBRlx8fu8/KroMPITXMd7WjiwU4tZkKqeKgbwiTykHj/41/qRxlBVG7/7L72EO+ZMEPbUgbUwCsd3sgPigXsYh05X1ehUesL8/dsT/G/lSQtidQtSspKu2U9QmfJzQUi4141XlbNV/lACqm16uZWtFwiU6jmW9e7fpNDmK7AlLESrNCbT2gAPfi+5ePG1F8ILAW837rtUSajOlzr0efc9Jl0GcmCMWgQLdbF174KBWtHfgAe+cZfFmrq2gqCQpnVsMgy/iVjZ/L/cwBxVgb82k7c0l9BCHF9z0IYzQjcIb9WVdlaRuuAm5DgZgaPIH81dL370v/innIjhy2jBbYCiveLR5tWo4hU2fbPU6icPuI0zXaL/6SGj64WBwJTTjGH66KxPrWDq57isWuBGSr0E0eDMJn7fdd0SE6Lzd0Z06Lzd0Z06Lzd0Z06Lzd0Z06Lzd0Z06Lzd0Z06Lzd0Z06Lzd0Z06Lzd0Z0wR5vMNO+S3H1fyB0B93yjeS2qnvd0eSnRnvd0eSnRnvd0eSnRnvd0eSnRnvd0eSnRnvd0eSnRnvd0eSnRnvd0eSnRnvd0eSmCT3uSXkpgk97bgeSk7097dK8lMEnvcKjxGEMkOx153W7sded1u7HXndbux153W7sded1u7HXndbux153W7sded1u7HXndbuyOnUncOAAAA=)\n"
      ],
      "metadata": {
        "id": "vsNzsbZtaRXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x= torch.arange(1,10,1).reshape(1,3,3)\n",
        "x,x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPLhEwTbdE71",
        "outputId": "d96a1480-0106-44a8-b04c-7ac080e2df9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's index on our new tensor , middle bracket(dim=1), most inner bracket (last dim)\n",
        "x[0],x[0][0],x[0][0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-o5ikKWmOji",
        "outputId": "82e4c008-eaf8-47a2-f951-f5f7a354863e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]]),\n",
              " tensor([1, 2, 3]),\n",
              " tensor(1))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can use also use \" : \" to select \" all \" of a target dimension\n",
        "\n",
        "x[:,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8j4BZDCmynN",
        "outputId": "ffb01660-a2b0-4c84-cb08-fd226f2eb095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all  values of 0th and 1st dimension but only index 1 of 2nd dimension\n",
        "x[:,:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_SxVCHNp-By",
        "outputId": "9b311f87-e037-4133-864d-743202bba43c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get all values of the 0 dimension but only the first index value of 1st and 2nd dimension\n",
        "x[:,1,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRBdaR1RqSlH",
        "outputId": "1dcaf7e5-947f-4249-bda5-86b9793a56ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
        "x[0,0,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqreIoD-qvp-",
        "outputId": "0fffb373-40ce-4817-fa3f-f4d7441b255e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Index on x to return\n",
        "# a) 9\n",
        "x[:,2,2]\n",
        "# b)3,6,9\n",
        "x[0,:,2] # or x[:,:,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkJHWUf2rRDB",
        "outputId": "ef161a63-f7e8-4a95-a7ff-b1b0d3199f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 6, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch tensors and Numpy\n",
        "\n",
        "Numpy is popular scientifuc numerical computing library,\n",
        "And so this, Pytorch has functionality to interact with i\n",
        "* Data in Numpy, want in Pytorch tensor -> `torch.from_numpy(ndarray)`\n",
        "* Pytorch tensor -> Numpy -> `torch.Tensor.numpy()`\n",
        "\n",
        "Note : `numpy_tensor` points to the same memory location as `tensor`\n",
        "\n",
        "* `tensor + 1` creates a new tensor, so the original tensor and numpy_tensor are no longer connected.\n",
        "\n",
        "* `tensor += 1` modifies the tensor in-place, so numpy_tensor, which shares the same memory as tensor, also reflects the change."
      ],
      "metadata": {
        "id": "Ic_pA9u7rsuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy Array\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "array = np.arange(1.0,8.0)\n",
        "tensor = torch.from_numpy(array).type(torch.float32)\n",
        "array, tensor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX0pIiEuMxy2",
        "outputId": "27f431af-b78d-4e66-ab47-28923fbb98b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array.dtype , tensor.dtype\n",
        "\n",
        "# By default numpy datatype is float64 and torch is float32 s pytorch reflects default numpy's dt unless specified\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zthn-8ZINSIK",
        "outputId": "2ff3f721-99b2-4a84-9bbe-570880b5b078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('float64'), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the value of array what it will do `Tensor`?\n",
        "array+=1\n",
        "array,tensor\n",
        "# doesn't change in tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oe5Xl7HN52c",
        "outputId": "abb33969-ed3f-4275-dec4-f72158f05f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor to Numpy array\n",
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "tensor, numpy_tensor , tensor.dtype , numpy_tensor.dtype\n",
        "\n",
        "# Numpy as well reflects by default datatype of pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5aizWuTOklz",
        "outputId": "c34efc77-620c-4604-a4dd-4e72ba2eca71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32),\n",
              " torch.float32,\n",
              " dtype('float32'))"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the tensor what happens to`Numpy`?\n",
        "\n",
        "tensor = tensor + 1\n",
        "tensor, numpy_tensor\n",
        "#  tensor+=1 in-place changes hence reflects numpy as well as they share same memory location pointer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "117sloSWO4-h",
        "outputId": "001e9c1f-7c92-4012-eb85-994c24a3f4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reproducibility (trying to take random out of random)\n",
        "\n",
        "In short how a neural network learns:\n",
        "\n",
        "`start with random numbers -> tensor operations -> update random numbers to try and make them better representation of the data -> again -> again -> again ...`\n",
        "\n",
        "To reduce randomness in NN and Pytorch comes the concept of **random seed**\n",
        "\n",
        "Essentially what random seed does is \"flavour\" the randomness\n",
        "\n",
        "\n",
        "ref: https://en.wikipedia.org/wiki/Random_seed"
      ],
      "metadata": {
        "id": "NOXEie_RQIaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor_A = torch.rand(3,4)\n",
        "random_tensor_B = torch.rand(3,4)\n",
        "\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "\n",
        "print(random_tensor_A==random_tensor_B)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHRr5CBIRCvS",
        "outputId": "ff2df33d-b218-47fa-f45e-bb9bfd1989a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1827, 0.4280, 0.8703, 0.1593],\n",
            "        [0.0921, 0.7645, 0.7093, 0.9773],\n",
            "        [0.1120, 0.5022, 0.7302, 0.0725]])\n",
            "tensor([[0.5570, 0.0231, 0.7935, 0.9912],\n",
            "        [0.4541, 0.1849, 0.2803, 0.5116],\n",
            "        [0.5389, 0.2027, 0.2640, 0.1772]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make some random but reproducable tensors\n",
        "\n",
        "# set the random seed and to use it add above rand tensor creation\n",
        "RANDOM_SEED = 369\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3,4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_D = torch.rand(3,4)\n",
        "\n",
        "print(random_tensor_C)\n",
        "print(random_tensor_D)\n",
        "\n",
        "print(random_tensor_C==random_tensor_D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vAa5ZKTRInU",
        "outputId": "f126b2bf-ca10-423b-d7ee-a8eac5ca4456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3998, 0.6201, 0.9229, 0.0735],\n",
            "        [0.8979, 0.8878, 0.9014, 0.5796],\n",
            "        [0.4578, 0.3855, 0.9865, 0.2216]])\n",
            "tensor([[0.3998, 0.6201, 0.9229, 0.0735],\n",
            "        [0.8979, 0.8878, 0.9014, 0.5796],\n",
            "        [0.4578, 0.3855, 0.9865, 0.2216]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running tensor and pytorch objects on GPUs (and making faster compution)\n",
        "\n",
        "GPUs = faster computation on  numbers, thanks to cuda + NVIDIA hardware + Pytorch working behind scenes to make everything hunky dory (good)"
      ],
      "metadata": {
        "id": "m7pmMYMmTHsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Getting GPU\n",
        "1. Easiest = Use Google Colab  for a free  GPU (options to upgrade as well)\n",
        "2. use your own GPU - takes a bit setups and require investmen of Purchasing GPU, many opts\n",
        "\n",
        ": See this post for ref: https://timdettmers.com/category/deep-learning/\n",
        "\n",
        "3. Use Cloud Computing GCP , AWS , AZURE - can lend GPUs on cloud and use 'em\n",
        "\n",
        "for 2,3 Pytorch + GPU drivers (CUDA) takes bit setup , doc ref: https://pytorch.org/get-started/locally/"
      ],
      "metadata": {
        "id": "Kw6IVM40Tn8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check for GPU access with Pytorch\n",
        "\n",
        "* For pytorch since it's capable of running compute on GPU or CPU , it's best practice to setup device agnbostic code : https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code\n",
        "\n",
        "E.g. : run on GPU if available, else default to CPU"
      ],
      "metadata": {
        "id": "NAv1VoS6WV3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU access with PyTorch\n",
        "import torch\n",
        "!nvidia-smi\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgE79TKIlFEB",
        "outputId": "a6175468-374b-4fa3-eecb-6ad7cda4a02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Setup Device agnostic code\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "B0Z5vizElaH8",
        "outputId": "20d83637-1f11-4bc3-99b5-852fbb4bd1f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count  number of device\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_ELZ5Ib2OAX",
        "outputId": "99eb4ec3-3494-4af4-a345-e8118ec0637a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Putting tensors (and models) on the GPU\n",
        "The reason we want our tensors/models on GPU is because using a GPU results in faster computation"
      ],
      "metadata": {
        "id": "EpvrLyqP2UOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# By default tensor is on CPU\n",
        "tensor = torch.tensor([1,2,3], device=\"cpu\")\n",
        "# tensor not on GPU\n",
        "print(tensor, tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vozoJxlC3t0D",
        "outputId": "1bc4928d-6afb-4684-e753-70ac854c8813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move tensor to gpu (if available)\n",
        "\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqAwZhXT4LGJ",
        "outputId": "f410c959-3b17-4d33-86f1-f20c34dfb238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Moving tesors back to cpu"
      ],
      "metadata": {
        "id": "7QPRdg8i4g6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  If Tensor is on GPU, can't transform it to Numpy\n",
        "\n",
        "tensor_on_gpu.numpy()\n",
        "\n",
        "# TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIXfBAoY40dA",
        "outputId": "d86203ae-046d-4466-f88d-7d6306dd3393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To fix the GPU tensor with numpy issue, we can first set it on CPu\n",
        "\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6SUNxC47bO3",
        "outputId": "40ba05f6-560d-4425-bf9c-ef07c22b45b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercises and Extra curriculums\n",
        "\n",
        "ref: * https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb\n",
        "\n",
        "* https://pytorch.org/tutorials/beginner/basics/intro.html"
      ],
      "metadata": {
        "id": "IvFRLkoi7qiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantised Data version Normal Data and What makes it differ with process called Compression\n",
        "\n",
        "* Basically, we deliberately reduce the precision of normal data `(16-bit, 32-bit , 64-bit)` and convert to less precised data i.e. `8-bit` which\n",
        "  helps the Machine Learning Models and NN to perform optimistically well\n",
        "\n",
        "* We use quantization in machine learning, signal processing, and embedded systems because it reduces memory and computation requirements, even if it means a slight loss in accuracy, which is acceptable in many real-world applications.\n",
        "* Compression is a process of reducing the signal or information into smaller part without compromising the information or loss of data\n",
        "* Compression is about reducing the size of data, either without loss (lossless) or with acceptable loss (lossy)."
      ],
      "metadata": {
        "id": "YLzPa1y9Aaat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor with shape (7, 7)\n",
        "import torch\n",
        "\n",
        "tensor7 = torch.rand(7,7)\n",
        "tensor7.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRI1EEpm4rjD",
        "outputId": "2c0c48b4-1f5a-4012-ea1c-bc094fa0718c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a matrix multiplication on the tensor from 2 with another random tensor with shape (1, 7) (hint: you may have to transpose the second tensor).\n",
        "\n",
        "mat1 = torch.rand(1,7)\n",
        "mat2 = torch.transpose(mat1,0,1)\n",
        "# mat3 = mat1*mat2  this is element wise multiplication\n",
        "mat3 = mat1 @ mat2\n",
        "mat3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ySnK3l95C_P",
        "outputId": "6327e742-0898-4f26-acaf-9bd2e3044bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5188]])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed to 0 and do exercises 2 & 3 over again.\n",
        "\n",
        "RAND_SEED = 0\n",
        "torch.manual_seed(RAND_SEED)\n",
        "mat1 = torch.rand(7,7)\n",
        "\n",
        "print(mat1,\"\\n\")\n",
        "\n",
        "torch.manual_seed(RAND_SEED)\n",
        "mat2 = torch.rand(1,7)\n",
        "\n",
        "print(mat2,\"\\n\")\n",
        "\n",
        "mat3 = mat1 @ torch.transpose(mat2,0,1)\n",
        "\n",
        "print(mat3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_rpCc3m5xd4",
        "outputId": "ddffe0b6-b3e3-4510-fc36-d9df04c798d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901],\n",
            "        [0.8964, 0.4556, 0.6323, 0.3489, 0.4017, 0.0223, 0.1689],\n",
            "        [0.2939, 0.5185, 0.6977, 0.8000, 0.1610, 0.2823, 0.6816],\n",
            "        [0.9152, 0.3971, 0.8742, 0.4194, 0.5529, 0.9527, 0.0362],\n",
            "        [0.1852, 0.3734, 0.3051, 0.9320, 0.1759, 0.2698, 0.1507],\n",
            "        [0.0317, 0.2081, 0.9298, 0.7231, 0.7423, 0.5263, 0.2437],\n",
            "        [0.5846, 0.0332, 0.1387, 0.2422, 0.8155, 0.7932, 0.2783]]) \n",
            "\n",
            "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901]]) \n",
            "\n",
            "tensor([[1.5985],\n",
            "        [1.1173],\n",
            "        [1.2741],\n",
            "        [1.6838],\n",
            "        [0.8279],\n",
            "        [1.0347],\n",
            "        [1.2498]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Speaking of random seeds, we saw how to set it with torch.manual_seed() but is there a GPU equivalent? (hint: you'll need to look into the documentation for torch.cuda for this one). If there is, set the GPU random seed to 1234.\n",
        "\n",
        "import torch\n",
        "\n",
        "GPU_RANDON_SEED = torch.cuda.manual_seed(1234)\n",
        "\n",
        "# For setting all GPUs the same random seed we use this expression\n",
        "# torch.cuda.manual_seed_all(1234)\n",
        "\n",
        "# print(f\"{GPU_RANDON_SEED}\")  this doesn't works\n",
        "print(f\"Current GPU random seed: {torch.cuda.initial_seed()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "GnjG-D0m7QeV",
        "outputId": "622a966e-6ab7-4dbe-d2a3-3f92f5da3479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-25bbe51f7d70>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# print(f\"{GPU_RANDON_SEED}\")  this doesn't works\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Current GPU random seed: {torch.cuda.initial_seed()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36minitial_seed\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0meagerly\u001b[0m \u001b[0minitializes\u001b[0m \u001b[0mCUDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \"\"\"\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mdefault_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two random tensors of shape (2, 3) and send them both to the GPU (you'll need access to a GPU for this). Set torch.manual_seed(1234) when creating the tensors (this doesn't have to be the GPU random seed).\n",
        "\n",
        "GPU_RANDON_SEED = torch.cuda.manual_seed(1234)\n",
        "tensor_on_GPU_1 = torch.rand(2,3,device = \"cuda\")\n",
        "\n",
        "GPU_RANDON_SEED = torch.cuda.manual_seed(1234)\n",
        "tensor_on_GPU_2 = torch.rand(2,3, device = \"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "OUghKpw-8eun",
        "outputId": "2b1f3289-0709-4fe3-a8e7-16f2f171a8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-082fc3c0ec46>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mGPU_RANDON_SEED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtensor_on_GPU_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mGPU_RANDON_SEED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors).\n",
        "\n",
        "tensor_mult_on_gpu = tensor_on_GPU_1 @ torch.transpose(tensor_on_GPU_2 , 0 ,1)\n",
        "tensor_mult_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "Wt2fOjFO9kQn",
        "outputId": "0caf42c7-2cfa-401d-ba67-b20d9ae72cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tensor_on_GPU_1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-ea9a28170c19>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtensor_mult_on_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_on_GPU_1\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_on_GPU_2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtensor_mult_on_gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tensor_on_GPU_1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the maximum and minimum values of the output of 7.\n",
        "max_val = torch.max(tensor_mult_on_gpu)\n",
        "min_val = torch.min(tensor_mult_on_gpu)\n",
        "\n",
        "print(f\"Resp. Minimum and Maximum value of resultant multiplication matrix are: {min_val} & {max_val} \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "fxXbkQbq97ce",
        "outputId": "727afa55-741c-4c60-ee88-ba8609aae910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tensor_mult_on_gpu' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-b2806ae75621>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find the maximum and minimum values of the output of 7.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmax_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_mult_on_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmin_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_mult_on_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Resp. Minimum and Maximum value of resultant multiplication matrix are: {min_val} & {max_val} \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tensor_mult_on_gpu' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the maximum and minimum index values of the output of 7\n",
        "\n",
        "max_val_idx = torch.argmax(tensor_mult_on_gpu)\n",
        "min_val_idx = torch.argmin(tensor_mult_on_gpu)\n",
        "\n",
        "\n",
        "print(f\"Resp. Minimum and Maximum index value of resultant multiplication matrix are: {min_val_idx} & {max_val_idx} \")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "wEAoksZC-oTI",
        "outputId": "0a3dfa3c-c568-4c96-b9eb-04b22de547d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tensor_mult_on_gpu' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-dcbd27d34cb6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find the maximum and minimum index values of the output of 7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmax_val_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_mult_on_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmin_val_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_mult_on_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tensor_mult_on_gpu' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a random tensor with shape (1, 1, 1, 10) and then create a new tensor with all the 1 dimensions removed to be left with a tensor of shape (10). Set the seed to 7 when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape.\n",
        "RAND_SEED = 7\n",
        "torch.manual_seed(RAND_SEED)\n",
        "rand_tensor = torch.rand(1,1,1,10)\n",
        "print(f\"tensor: {rand_tensor}\\nit's shape : {rand_tensor.shape}\")\n",
        "torch.manual_seed(RAND_SEED)\n",
        "new_tensor = torch.squeeze(rand_tensor)\n",
        "print(f\"tensor: {new_tensor}\\nit's shape : {new_tensor.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmbo9saH_Qup",
        "outputId": "ac48550d-021c-42d6-c92e-92694c706d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor: tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
            "           0.3653, 0.8513]]]])\n",
            "it's shape : torch.Size([1, 1, 1, 10])\n",
            "tensor: tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
            "        0.8513])\n",
            "it's shape : torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  "
      ],
      "metadata": {
        "id": "g4e7CFeQAVjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J1fq2WqqDb_S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}